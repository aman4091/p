#!/usr/bin/env python3
import os
import json
import asyncio
import logging
import requests
import torch
from pathlib import Path
import telegram
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
import whisper
from datetime import datetime
import time
import glob
import shutil
import subprocess
import re
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Auto-set environment variables if not already set
def auto_set_env_vars():
    """Automatically set environment variables if missing"""
    default_env_vars = {
        "DEEPSEEK_API_KEY": "sk-299e2e942ec14e35926666423990d968",
        "SUPADATA_API_KEY": "sd_a3a69115625b5507719678ab42a7dd71",
        "IMAGE_SHORTS_CHAT_ID": "-1002343932866",
        "IMAGE_LONG_CHAT_ID": "-1002498893774",
        "GDRIVE_FOLDER_LONG": "1y-Af4T5pAvgqV2gyvN9zhSPdvZzUcFyi",
        "GDRIVE_FOLDER_SHORT": "1JdJCYDXLWjAz1091zs_Pnev3FuK3Ftex",
        "CHANNEL_MODE_ENABLED": "true",
        "CHANNEL_IDS": "-1002498893774"
    }

    auto_set_count = 0
    for key, value in default_env_vars.items():
        if not os.getenv(key):
            os.environ[key] = value
            auto_set_count += 1

    if auto_set_count > 0:
        print(f"\n{'='*50}")
        print(f"üîß AUTO-CONFIGURED ENVIRONMENT")
        print(f"{'='*50}")
        print(f"‚úÖ Automatically set {auto_set_count} environment variables")
        print(f"   (Including CHANNEL_MODE_ENABLED and CHANNEL_IDS)")
        print(f"{'='*50}\n")

# Auto-set environment variables on startup
auto_set_env_vars()

# Logging setup
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ‚ö†Ô∏è YE VALUES APNI DETAILS SE CHANGE KARIYE
BOT_TOKEN = "8274226808:AAH0NQWBf9DF-nZpbOSbl4SkcCkcp8HMmDY"
CHAT_ID = "447705580"  # Updated to correct chat ID

# Channel Configuration
CHANNEL_MODE_ENABLED = os.getenv("CHANNEL_MODE_ENABLED", "false").lower() == "true"
CHANNEL_IDS_STR = os.getenv("CHANNEL_IDS", "")
CHANNEL_IDS = [int(ch_id.strip()) for ch_id in CHANNEL_IDS_STR.split(",") if ch_id.strip() and ch_id.strip().lstrip('-').isdigit()]

# Configuration
REFERENCE_DIR = "reference"
OUTPUT_DIR = "output"
SCRIPTS_DIR = "scripts"
MAX_TELEGRAM_FILE_SIZE = 50 * 1024 * 1024  # 50MB

# Directories banayiye
os.makedirs(REFERENCE_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(SCRIPTS_DIR, exist_ok=True)

class WorkingF5Bot:
    def __init__(self):
        print("üîÑ Working F5-TTS Bot initializing...")
        self.whisper_model = None
        self.f5_model = None
        self.reference_audio = None
        self.reference_text = None
        self.processing_queue = []
        self.completed_files = []  # Track completed files with links
        self.is_processing = False
        self.stop_requested = False  # Add stop flag
        self.gofile_cache = {}
        self.latest_outputs_by_chat = {}

        # Queue batch processing settings
        self.queue_timer = None
        self.queue_wait_time = 120  # 2 minutes wait before processing
        self.queue_start_time = None
        self.batch_mode = False  # True when collecting files for batch
        self.power_policy = "off"    # off | stop | destroy
        self.shutdown_executed = False
        self.delivery_prefs_by_chat = {}

        # Initialize defaults before loading config
        self.deepseek_prompt = "Rewrite this content to be more engaging:"
        self.youtube_transcript_prompt = "Rewrite this YouTube transcript content to be more engaging and natural for text-to-speech:"
        self.ai_mode = "deepseek"  # "deepseek" or "openrouter" - for YouTube transcript processing only
        self.openrouter_model = "deepseek/deepseek-chat"  # Default OpenRouter model
        self.ffmpeg_filter = "afftdn=nr=12:nf=-25,highpass=f=80,lowpass=f=10000,equalizer=f=6000:t=h:width=2000:g=-6"
        self.audio_speed = 0.8
        self.audio_quality = 'high'
        self.chunk_size = 500  # Audio generation chunk size (chars). Higher = faster but lower quality. 4090 can handle 2000+

        # Title generation prompts for DeepSeek
        self.title_prompt_1 = "Based on the following script, generate 1 catchy and engaging title for a video. The title should be attention-grabbing, relevant to the content, and optimized for social media. Keep it concise (under 60 characters). Only return the title, nothing else.\n\nScript:"
        self.title_prompt_2 = "The previous title suggestion was good, but let's refine it further. Make it more engaging, compelling, and click-worthy while maintaining relevance to the script. Keep it under 60 characters. Only return the refined title, nothing else.\n\nPrevious title:"
        self.title_prompt_3 = "This is the final refinement. Polish the title to perfection - make it irresistible while staying true to the content. Ensure it's optimized for maximum engagement. Keep it under 60 characters. Only return the final polished title, nothing else.\n\nPrevious refined title:"
        self.title_prompt_10_more = "Based on the following script, generate 10 different catchy and engaging titles for a video. Each title should be unique, attention-grabbing, and optimized for social media. Keep each title concise (under 60 characters). Number them 1-10, one per line.\n\nScript:"

        # Title generation state tracking
        self.title_generation_state = {}  # {chat_id: {'stage': 'initial'/'refine1'/'refine2', 'title': '...', 'script': '...'}}

        # Configuration file
        self.config_file = "bot_config.json"

        # Load configuration from file (will override defaults if exists)
        self.load_config()

        # Initialize F5-TTS
        self.init_f5_tts()
        
        # Load reference
        self.load_manual_reference()
        self.vast_env_ok = self.check_vast_environment()
        self.api_keys_ok = self.check_api_keys()
        
    async def _send_chunk_update(self, chat_id, current_chunk, total_chunks):
        """Send chunk progress update to Telegram"""
        try:
            from telegram import Bot
            bot = Bot(token=BOT_TOKEN)
            progress_text = f"üîÑ Processing chunk {current_chunk}/{total_chunks}..."
            await bot.send_message(
                chat_id=chat_id,
                text=progress_text
            )
        except Exception as e:
            print(f"Chunk update error: {e}")

    def check_vast_environment(self):
        """Check if Vast.ai environment variables are properly set"""
        issues = []
        
        # Check API key
        if not os.getenv("VAST_API_KEY"):
            issues.append("VAST_API_KEY not set")
        
        # Check instance ID  
        if not (os.getenv("VAST_INSTANCE_ID") or os.getenv("CONTAINER_ID")):
            issues.append("VAST_INSTANCE_ID or CONTAINER_ID not set")
        
        # Check if vastai CLI is available
        try:
            import subprocess
            subprocess.run(["vastai", "--version"], capture_output=True, timeout=10)
        except Exception:
            issues.append("vastai CLI not installed or not in PATH")
        
        if issues:
            print("‚ö†Ô∏è Vast.ai environment issues:")
            for issue in issues:
                print(f"  - {issue}")
            return False
        else:
            print("‚úÖ Vast.ai environment properly configured")
            return True

    def is_channel_message(self, update: Update):
        """Check if message is from a channel"""
        if not update.effective_chat:
            return False
        return update.effective_chat.type == "channel"

    def is_authorized_channel(self, chat_id):
        """Check if channel is authorized to use bot"""
        if not CHANNEL_MODE_ENABLED:
            return False

        # If no channel IDs configured, allow all channels
        if not CHANNEL_IDS:
            return True

        # Check if channel ID is in authorized list
        return chat_id in CHANNEL_IDS

    async def send_message_smart(self, context, chat_id, text, **kwargs):
        """Send message with channel/private chat awareness"""
        try:
            await context.bot.send_message(
                chat_id=chat_id,
                text=text,
                **kwargs
            )
        except Exception as e:
            print(f"‚ùå Send message error: {e}")
            # Fallback to original CHAT_ID if channel send fails
            try:
                await context.bot.send_message(
                    chat_id=CHAT_ID,
                    text=f"‚ö†Ô∏è Channel message failed. Sending to DM:\n\n{text}",
                    **kwargs
                )
            except Exception as e2:
                print(f"‚ùå Fallback send also failed: {e2}")

    async def cleanup_old_files(self, max_age_hours=2):
        """Remove files older than specified hours to save storage costs"""
        try:
            current_time = time.time()
            cutoff_time = current_time - (max_age_hours * 3600)
            
            # Clean output directory
            for file_path in glob.glob(os.path.join(OUTPUT_DIR, "*")):
                if os.path.getctime(file_path) < cutoff_time:
                    os.remove(file_path)
                    print(f"Cleaned old file: {os.path.basename(file_path)}")
            
            # Clean scripts directory  
            for file_path in glob.glob(os.path.join(SCRIPTS_DIR, "*.txt")):
                if os.path.getctime(file_path) < cutoff_time:
                    os.remove(file_path)
                    print(f"Cleaned old script: {os.path.basename(file_path)}")
                    
            print("File cleanup completed")
        except Exception as e:
            print(f"Cleanup error: {e}")
        
    async def deep_cleanup_storage(self):
        """Aggressive storage cleanup to reduce costs"""
        try:
            print("üßπ Starting deep storage cleanup...")
            
            # 1. Clean output directory completely
            for file_path in glob.glob(os.path.join(OUTPUT_DIR, "*")):
                try:
                    os.remove(file_path)
                    print(f"Deleted: {os.path.basename(file_path)}")
                except Exception:
                    pass
            
            # 2. Clean scripts directory
            for file_path in glob.glob(os.path.join(SCRIPTS_DIR, "*")):
                try:
                    os.remove(file_path)
                    print(f"Deleted script: {os.path.basename(file_path)}")
                except Exception:
                    pass
            
            # 3. Clean old reference files (keep only current one)
            for file_path in glob.glob(os.path.join(REFERENCE_DIR, "*")):
                if file_path != self.reference_audio:
                    try:
                        os.remove(file_path)
                        print(f"Deleted old ref: {os.path.basename(file_path)}")
                    except Exception:
                        pass
            
            # 4. Clean system temp files
            temp_patterns = [
                "/tmp/*f5*", "/tmp/*audio*", "/tmp/*wav*", "/tmp/*mp3*",
                "*.tmp", "*.temp", "*~"
            ]
            for pattern in temp_patterns:
                for file_path in glob.glob(pattern):
                    try:
                        os.remove(file_path)
                        print(f"Deleted temp: {os.path.basename(file_path)}")
                    except Exception:
                        pass
            
            # 5. Empty trash if it exists
            trash_dirs = ["/root/.local/share/Trash", "/tmp/.trash", "/.trash"]
            for trash_dir in trash_dirs:
                if os.path.exists(trash_dir):
                    import shutil
                    try:
                        shutil.rmtree(trash_dir, ignore_errors=True)
                        os.makedirs(trash_dir, exist_ok=True)
                        print(f"Emptied trash: {trash_dir}")
                    except Exception:
                        pass
            
            # 6. Force disk sync
            try:
                import subprocess
                subprocess.run(["sync"], capture_output=True)
                print("‚úÖ Forced disk sync")
            except Exception:
                pass
            
            print("‚úÖ Deep cleanup completed")
            
        except Exception as e:
            print(f"‚ùå Deep cleanup error: {e}")

    def load_config(self):
        """Load configuration from file"""
        try:
            with open(self.config_file, 'r') as f:
                config = json.load(f)
                self.deepseek_prompt = config.get('deepseek_prompt', "Rewrite this content to be more engaging:")
                self.youtube_transcript_prompt = config.get('youtube_transcript_prompt', "Rewrite this YouTube transcript content to be more engaging and natural for text-to-speech:")
                self.ai_mode = config.get('ai_mode', 'deepseek')
                self.openrouter_model = config.get('openrouter_model', 'deepseek/deepseek-chat')
                self.audio_speed = config.get('audio_speed', 0.8)
                self.audio_quality = config.get('audio_quality', 'high')
                self.power_policy = config.get('power_policy', 'off')
                self.chunk_size = config.get('chunk_size', 500)

                # Load FFmpeg filter and clean it if it's a full command
                raw_filter = config.get('ffmpeg_filter', 'afftdn=nr=12:nf=-25,highpass=f=80,lowpass=f=10000,equalizer=f=6000:t=h:width=2000:g=-6')
                self.ffmpeg_filter = self._extract_ffmpeg_filter_static(raw_filter)
                filter_was_cleaned = (raw_filter != self.ffmpeg_filter)
                print(f"‚úÖ FFmpeg filter loaded: {self.ffmpeg_filter[:80]}...")
                if filter_was_cleaned:
                    print(f"üîß Filter was cleaned from full command")

                # Load title generation prompts
                self.title_prompt_1 = config.get('title_prompt_1', "Based on the following script, generate 1 catchy and engaging title for a video. The title should be attention-grabbing, relevant to the content, and optimized for social media. Keep it concise (under 60 characters). Only return the title, nothing else.\n\nScript:")
                self.title_prompt_2 = config.get('title_prompt_2', "The previous title suggestion was good, but let's refine it further. Make it more engaging, compelling, and click-worthy while maintaining relevance to the script. Keep it under 60 characters. Only return the refined title, nothing else.\n\nPrevious title:")
                self.title_prompt_3 = config.get('title_prompt_3', "This is the final refinement. Polish the title to perfection - make it irresistible while staying true to the content. Ensure it's optimized for maximum engagement. Keep it under 60 characters. Only return the final polished title, nothing else.\n\nPrevious refined title:")
                self.title_prompt_10_more = config.get('title_prompt_10_more', "Based on the following script, generate 10 different catchy and engaging titles for a video. Each title should be unique, attention-grabbing, and optimized for social media. Keep each title concise (under 60 characters). Number them 1-10, one per line.\n\nScript:")

                # Debug logging for title prompts
                print(f"‚úÖ Title Prompt 1 loaded: {self.title_prompt_1[:50]}...")
                print(f"‚úÖ Title Prompt 2 loaded: {self.title_prompt_2[:50]}...")
                print(f"‚úÖ Title Prompt 3 loaded: {self.title_prompt_3[:50]}...")
                print(f"‚úÖ Title Prompt 10 More loaded: {self.title_prompt_10_more[:50]}...")

                # Load delivery preferences if available
                if 'delivery_prefs' in config:
                    self.delivery_prefs_by_chat = config['delivery_prefs']

            print(f"‚úÖ Configuration loaded from {self.config_file}")

            # Save config if filter was cleaned
            if filter_was_cleaned:
                print(f"üíæ Saving cleaned filter to config...")
                self.save_config()
        except FileNotFoundError:
            # Config file doesn't exist - defaults already set in __init__
            print(f"‚ÑπÔ∏è Config file not found, using defaults")
            self.save_config()
        except json.JSONDecodeError:
            print(f"‚ö†Ô∏è Invalid JSON in config file, using defaults")
            self.save_config()
        except Exception as e:
            print(f"‚ö†Ô∏è Config load error: {e}, using defaults")
    
    def save_config(self):
        """Save configuration to file"""
        try:
            config = {
                'deepseek_prompt': self.deepseek_prompt,
                'youtube_transcript_prompt': self.youtube_transcript_prompt,
                'ai_mode': self.ai_mode,
                'openrouter_model': self.openrouter_model,
                'audio_speed': self.audio_speed,
                'audio_quality': self.audio_quality,
                'power_policy': self.power_policy,
                'chunk_size': self.chunk_size,
                'ffmpeg_filter': self.ffmpeg_filter,
                'delivery_prefs': self.delivery_prefs_by_chat,
                'title_prompt_1': self.title_prompt_1,
                'title_prompt_2': self.title_prompt_2,
                'title_prompt_3': self.title_prompt_3,
                'title_prompt_10_more': self.title_prompt_10_more
            }
            with open(self.config_file, 'w') as f:
                json.dump(config, f, indent=2)
            print(f"‚úÖ Configuration saved to {self.config_file}")
        except Exception as e:
            print(f"‚ùå Config save error: {e}")
            
    def check_api_keys(self):
        """Check if required API keys are set"""
        missing_keys = []
        
        if not os.getenv("SUPADATA_API_KEY"):
            missing_keys.append("SUPADATA_API_KEY")
        
        if not os.getenv("DEEPSEEK_API_KEY"):
            missing_keys.append("DEEPSEEK_API_KEY")
        
        if missing_keys:
            print(f"‚ö†Ô∏è Missing API keys: {', '.join(missing_keys)}")
            print("Set them with:")
            for key in missing_keys:
                print(f"export {key}='your_key_here'")
            return False
        
        print("‚úÖ All API keys configured")
        return True

    def debug_api_setup(self):
        """Debug API key setup"""
        api_key = os.getenv("SUPADATA_API_KEY")
        
        if not api_key:
            print("‚ùå SUPADATA_API_KEY environment variable not found")
            return False
        
        print(f"‚úÖ API Key found: {len(api_key)} characters")
        print(f"üîë Key preview: {api_key[:8]}{'*' * (len(api_key) - 8)}")
        
        # Check for common issues
        if ' ' in api_key:
            print("‚ö†Ô∏è API key contains spaces")
        if '\n' in api_key:
            print("‚ö†Ô∏è API key contains newlines")
        if api_key.startswith('"') or api_key.endswith('"'):
            print("‚ö†Ô∏è API key has quotes")
            
        return True

    async def process_multiple_youtube_links(self, youtube_links, update, context):
        """Process multiple YouTube links sequentially"""
        try:
            total_links = len(youtube_links)
            await update.message.reply_text(
                f"üîó Found {total_links} YouTube link(s) to process\n"
                f"‚è≥ Processing them sequentially..."
            )
            
            results = []
            for idx, link in enumerate(youtube_links, 1):
                await update.message.reply_text(
                    f"\nüìå **Processing Link {idx}/{total_links}**\n"
                    f"üîó {link[:50]}{'...' if len(link) > 50 else ''}",
                    parse_mode="Markdown"
                )
                
                script_path, audio_files = await self.process_youtube_link(link, update, context)
                
                if script_path or audio_files:
                    results.append({
                        'link': link,
                        'script': script_path,
                        'audio': audio_files,
                        'index': idx
                    })
                    
                # Small delay between processing links
                if idx < total_links:
                    await asyncio.sleep(2)
            
            # Summary message
            if results:
                summary = f"\n‚úÖ **Processing Complete!**\n"
                summary += f"üìä Successfully processed {len(results)}/{total_links} link(s)\n\n"
                
                for result in results:
                    summary += f"Link {result['index']}: ‚úÖ Script + Audio generated\n"
                
                await update.message.reply_text(summary, parse_mode="Markdown")
            else:
                await update.message.reply_text("‚ùå Failed to process any links")
                
        except Exception as e:
            await update.message.reply_text(f"‚ùå Multiple links processing error: {str(e)}")
    
    async def process_youtube_link(self, youtube_url, update, context):
        """Process YouTube link through SupaData API + DeepSeek API"""
        try:
            # Handle both regular messages and callback queries
            if hasattr(update, 'callback_query') and update.callback_query:
                chat_id = update.callback_query.message.chat.id
                # For callbacks, send new messages instead of replying
                send_message = lambda text: context.bot.send_message(chat_id=chat_id, text=text)
            else:
                chat_id = update.effective_chat.id
                # For regular messages, use reply_text
                send_message = update.message.reply_text
            
            await send_message("üîó Processing YouTube link...")
            
            # Step 1: Get transcript from SupaData API
            transcript = await self.get_youtube_transcript(youtube_url)
            if not transcript:
                await send_message("‚ùå Could not get YouTube transcript")
                return None, None
            
            await send_message(f"‚úÖ Transcript retrieved ({len(transcript)} chars)")

            # Step 2: Process through selected AI (DeepSeek or OpenRouter) with YouTube-specific prompt
            if self.ai_mode == "openrouter":
                await send_message(f"ü§ñ Using OpenRouter AI mode...")
                processed_script = await self.process_with_openrouter(transcript, chat_id, context, self.youtube_transcript_prompt)
            else:
                await send_message(f"ü§ñ Using DeepSeek AI mode...")
                processed_script = await self.process_with_deepseek(transcript, chat_id, context, self.youtube_transcript_prompt)

            if not processed_script:
                await send_message(f"‚ùå {self.ai_mode.capitalize()} processing failed")
                return None, None
            
            # Step 3: Save processed script to file
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            script_filename = f"deepseek_script_{timestamp}.txt"
            script_path = os.path.join(SCRIPTS_DIR, script_filename)
            
            with open(script_path, 'w', encoding='utf-8') as f:
                f.write(processed_script)
            
            # Step 4: Send script directly through Telegram (no GoFile upload)
            try:
                with open(script_path, 'rb') as f:
                    await context.bot.send_document(
                        chat_id=chat_id,
                        document=f,
                        filename=script_filename,
                        caption=f"üìù **DeepSeek Processed Script**\n"
                               f"üìÑ File: {script_filename}\n"
                               f"üìè Size: {len(processed_script)} chars\n"
                               f"‚úÖ Ready for F5-TTS processing"
                    )
                print(f"‚úÖ Script sent via Telegram: {script_filename}")
            except Exception as e:
                print(f"‚ùå Failed to send script via Telegram: {e}")
                try:
                    if len(processed_script) <= 4000:
                        await send_message(f"üìù **DeepSeek Processed Script**\n\n{processed_script[:4000]}")
                    else:
                        await send_message(f"üìù Script too long to send as message. Saved locally as {script_filename}")
                except Exception as e2:
                    print(f"‚ùå Failed to send script as message: {e2}")
            
            # Step 5: Generate audio with F5-TTS
            await send_message("üéµ Generating audio...")
            success, output_files = await self.generate_audio_f5(processed_script, chat_id)
            
            if success:
                await self.send_outputs_by_mode(context, chat_id, output_files, processed_script, "YouTube Audio")
            else:
                await send_message(f"‚ùå Audio generation failed: {output_files}")
            
            # Step 6: Cleanup everything except audio and script
            await self.cleanup_processing_files(exclude_scripts=True)
            
            return script_path, output_files if success else None
            
        except Exception as e:
            error_msg = f"‚ùå YouTube processing error: {str(e)}"
            print(error_msg)
            
            # Handle error messaging for both types
            try:
                if hasattr(update, 'callback_query') and update.callback_query:
                    await context.bot.send_message(
                        chat_id=update.callback_query.message.chat.id,
                        text=error_msg
                    )
                else:
                    await update.message.reply_text(error_msg)
            except:
                print("Could not send error message to user")
            
            return None, None

    async def extract_youtube_audio_as_reference(self, youtube_url, update, context):
        """Extract audio from YouTube video and set it as reference (cropped to ~30 seconds)"""
        try:
            # Handle both regular messages and callback queries
            if hasattr(update, 'callback_query') and update.callback_query:
                chat_id = update.callback_query.message.chat.id
                message = update.callback_query.message
            else:
                chat_id = update.effective_chat.id
                message = update.message
            
            await context.bot.send_message(
                chat_id=chat_id,
                text="üéµ Extracting audio from YouTube video..."
            )
            
            # Download audio using yt-dlp
            try:
                import yt_dlp
            except ImportError:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text="‚ùå yt-dlp not installed!\n\nRun: pip install yt-dlp"
                )
                return False
            
            timestamp = int(time.time())
            temp_output_template = os.path.join(REFERENCE_DIR, f"temp_yt_audio_{timestamp}")
            
            ydl_opts = {
                'format': 'bestaudio/best',
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                    'preferredquality': '192',
                }],
                'outtmpl': temp_output_template,
                'quiet': False,
                'no_warnings': False,
                'extract_flat': False,
                # Updated headers to bypass YouTube's 403 blocks (Oct 2025)
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',
                'referer': 'https://www.youtube.com/',
                'http_headers': {
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.9',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none',
                    'Cache-Control': 'max-age=0',
                },
                # Enhanced retry options for 403 errors
                'retries': 10,
                'fragment_retries': 10,
                'skip_unavailable_fragments': True,
                'ignoreerrors': False,
                # Use extractor args for better compatibility
                'extractor_args': {
                    'youtube': {
                        'player_client': ['android', 'web'],
                        'player_skip': ['webpage', 'configs'],
                    }
                },
                # Sleep between retries
                'sleep_interval': 1,
                'max_sleep_interval': 5,
            }
            
            print(f"üì• Downloading audio from: {youtube_url}")
            
            try:
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    # First get info without downloading
                    info = ydl.extract_info(youtube_url, download=False)
                    
                    # Check if it's a live stream
                    if info.get('is_live') or info.get('live_status') in ['is_live', 'is_upcoming', 'live']:
                        await context.bot.send_message(
                            chat_id=chat_id,
                            text=(
                                "‚ùå Cannot extract audio from LIVE streams!\n\n"
                                "Please wait until the stream ends and becomes a regular video.\n\n"
                                "üî¥ This is a live broadcast that's currently streaming."
                            )
                        )
                        return False
                    
                    video_title = info.get('title', 'video')[:50]
                    # Now download
                    ydl.download([youtube_url])
            except Exception as yt_error:
                print(f"‚ùå yt-dlp error: {yt_error}")
                error_msg = str(yt_error)

                # Provide specific help based on error type
                if "403" in error_msg or "Forbidden" in error_msg:
                    help_text = (
                        "‚ùå YouTube Download Failed (403 Forbidden)\n\n"
                        "YouTube has blocked this request. Try these fixes:\n\n"
                        "üîß Solutions:\n"
                        "1Ô∏è‚É£ **Update yt-dlp** (Most Important!):\n"
                        "   Run: `pip install -U yt-dlp`\n"
                        "   Then restart the bot\n\n"
                        "2Ô∏è‚É£ **Wait 2-5 minutes** (YouTube rate limit)\n\n"
                        "3Ô∏è‚É£ **Try a different video**\n\n"
                        "4Ô∏è‚É£ **Check video availability** in your region\n\n"
                        "5Ô∏è‚É£ **Use a different format**: Try short videos (<10 min)\n\n"
                        "üìù Note: YouTube frequently updates their bot protection.\n"
                        "Always keep yt-dlp updated for best results.\n\n"
                        f"Technical Error: {error_msg[:100]}"
                    )
                elif "Private" in error_msg or "unavailable" in error_msg:
                    help_text = (
                        "‚ùå Video Not Available\n\n"
                        "This video is either:\n"
                        "‚Ä¢ Private\n"
                        "‚Ä¢ Deleted\n"
                        "‚Ä¢ Restricted\n"
                        "‚Ä¢ Not available in your region\n\n"
                        "Please try a public video."
                    )
                elif "Sign in" in error_msg:
                    help_text = (
                        "‚ùå Age Restricted Video\n\n"
                        "This video requires sign-in/age verification.\n"
                        "Bot cannot download age-restricted videos.\n\n"
                        "Try a different video."
                    )
                else:
                    help_text = (
                        f"‚ùå YouTube download failed!\n\n"
                        f"Error: {error_msg[:200]}\n\n"
                        f"üí° Try:\n"
                        f"‚Ä¢ Different video\n"
                        f"‚Ä¢ Update yt-dlp: pip install -U yt-dlp\n"
                        f"‚Ä¢ Wait a few minutes"
                    )

                await context.bot.send_message(
                    chat_id=chat_id,
                    text=help_text
                )
                return False
            
            # Find the downloaded file (yt-dlp adds .mp3 extension)
            temp_audio_path = f"{temp_output_template}.mp3"
            
            if not os.path.exists(temp_audio_path):
                # Try without extension
                if os.path.exists(temp_output_template):
                    temp_audio_path = temp_output_template
                else:
                    await context.bot.send_message(
                        chat_id=chat_id,
                        text=f"‚ùå Downloaded file not found!\n\nExpected: {temp_audio_path}"
                    )
                    return False
            
            print(f"‚úÖ Audio downloaded: {os.path.basename(temp_audio_path)}")
            
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"‚úÖ Audio extracted: {video_title}\n\nüé¨ Cropping to ~30 seconds..."
            )
            
            # Crop to 30 seconds using ffmpeg
            cropped_path = os.path.join(REFERENCE_DIR, f"ref_yt_{timestamp}.wav")
            
            try:
                crop_cmd = [
                    'ffmpeg', '-i', temp_audio_path,
                    '-t', '30',
                    '-ar', '24000',
                    '-ac', '1',
                    '-y', cropped_path
                ]
                
                result = subprocess.run(
                    crop_cmd, 
                    capture_output=True, 
                    check=True, 
                    timeout=60,
                    text=True
                )
                print(f"‚úÖ Audio cropped to 30s")
                
            except subprocess.TimeoutExpired:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text="‚ùå FFmpeg timeout! Audio file might be too large."
                )
                return False
            except subprocess.CalledProcessError as e:
                print(f"‚ùå FFmpeg error: {e.stderr}")
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=f"‚ùå Audio cropping failed!\n\nFFmpeg error: {e.stderr[:200]}"
                )
                return False
            except Exception as e:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=f"‚ùå Cropping error: {str(e)}"
                )
                return False
            
            # Remove temp file
            try:
                if os.path.exists(temp_audio_path):
                    os.remove(temp_audio_path)
                    print(f"üóëÔ∏è Cleaned temp file")
            except Exception as e:
                print(f"‚ö†Ô∏è Could not remove temp file: {e}")
            
            await context.bot.send_message(
                chat_id=chat_id,
                text="üé§ Extracting reference text with Whisper..."
            )
            
            # Extract text with Whisper
            try:
                if not self.whisper_model:
                    print("üì• Loading Whisper model...")
                    self.whisper_model = whisper.load_model("base", device="cpu")
                
                result = self.whisper_model.transcribe(cropped_path)
                new_ref_text = result["text"].strip()
                print(f"‚úÖ Whisper transcription: {new_ref_text[:100]}")
                
            except Exception as whisper_error:
                print(f"‚ùå Whisper error: {whisper_error}")
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=f"‚ùå Whisper transcription failed!\n\nError: {str(whisper_error)[:200]}"
                )
                return False
            
            # Delete old reference if not default
            if self.reference_audio and os.path.exists(self.reference_audio):
                old_filename = os.path.basename(self.reference_audio)
                if not old_filename.startswith('k.'):
                    try:
                        os.remove(self.reference_audio)
                        print(f"üóëÔ∏è Deleted old reference: {old_filename}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Could not delete old reference: {e}")
            
            # Update reference
            self.reference_audio = cropped_path
            self.reference_text = new_ref_text
            
            # Clear F5-TTS cache
            if hasattr(self.f5_model, '_cached_ref_audio'):
                delattr(self.f5_model, '_cached_ref_audio')
            if hasattr(self.f5_model, '_cached_ref_text'):
                delattr(self.f5_model, '_cached_ref_text')
            
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            import gc
            gc.collect()
            
            print(f"‚úÖ Reference audio updated successfully!")
            
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"‚úÖ Reference audio updated from YouTube!\n\n"
                     f"üé¨ Video: {video_title}\n"
                     f"üìÑ File: {os.path.basename(cropped_path)}\n"
                     f"‚è±Ô∏è Duration: ~30 seconds\n\n"
                     f"üìù Extracted text:\n{new_ref_text[:200]}{'...' if len(new_ref_text) > 200 else ''}\n\n"
                     f"‚úÖ Ready to use for voice cloning!"
            )
            
            return True
            
        except Exception as e:
            error_msg = f"‚ùå YouTube audio extraction error: {str(e)}"
            print(error_msg)
            import traceback
            print(traceback.format_exc())
            
            # Handle both message types for error reporting
            try:
                if hasattr(update, 'callback_query') and update.callback_query:
                    chat_id = update.callback_query.message.chat.id
                else:
                    chat_id = update.effective_chat.id
                    
                await context.bot.send_message(chat_id=chat_id, text=error_msg)
            except:
                print("Could not send error message to user")
            
            return False

    async def get_youtube_transcript(self, url):
        """Get transcript from SupaData API using correct implementation"""
        try:
            api_key = os.getenv("SUPADATA_API_KEY")
            if not api_key:
                print("‚ùå SUPADATA_API_KEY not set")
                return None

            print(f"üîÑ Getting transcript for: {url}")

            # Correct endpoint and headers from your working script
            api_url = "https://api.supadata.ai/v1/transcript"
            headers = {
                "x-api-key": api_key,  # Correct header format
                "Accept": "application/json"
            }

            # Correct parameters from your working script
            params = {
                "url": url,
                "text": True,  # Return plain text instead of timestamped chunks
                "mode": "auto"  # Try native first, fallback to AI generation
            }

            print(f"üîÑ Making GET request to SupaData API...")

            # Use GET request with params (not POST with JSON body)
            response = requests.get(
                api_url,
                params=params,
                headers=headers,
                timeout=1000
            )

            print(f"üìä SupaData response: {response.status_code}")

            if response.status_code == 401:
                print("‚ùå 401 Unauthorized - check API key")
                return None
            elif response.status_code == 202:
                # Async job - need to poll for results
                job_data = response.json()
                job_id = job_data.get("jobId")
                if not job_id:
                    print("‚ùå Got 202 but no job ID")
                    return None

                print(f"üîÑ Large file detected, polling job: {job_id}")
                return await self._poll_supadata_job(job_id, api_key)
            elif response.status_code >= 400:
                error_text = response.text[:200]
                print(f"‚ùå SupaData error {response.status_code}: {error_text}")
                return None
            elif response.status_code == 200:
                # Direct response - process transcript
                data = response.json()
                print(f"üîç Response type: {type(data)}")
                if isinstance(data, list):
                    print(f"üìä List with {len(data)} items")
                    if data:
                        print(f"First item type: {type(data[0])}")
                        if isinstance(data[0], dict):
                            print(f"First item keys: {list(data[0].keys())}")
                elif isinstance(data, dict):
                    print(f"üìä Dict with keys: {list(data.keys())}")
                
                transcript = self._extract_transcript_text(data)
                if transcript:
                    print(f"‚úÖ Transcript received: {len(transcript)} characters")
                    return transcript
                else:
                    print("‚ùå No transcript content found in response")
                    return None
            else:
                print(f"‚ùå Unexpected status code: {response.status_code}")
                return None

        except Exception as e:
            print(f"‚ùå SupaData error: {e}")
            return None

    async def get_youtube_transcript_fallback(self, url):
        """Fallback method with different endpoint structure"""
        try:
            api_key = os.getenv("SUPADATA_API_KEY")
            if not api_key:
                return None
            
            # Try alternative endpoint structure
            endpoints_to_try = [
                "https://api.supadata.ai/youtube/transcript",
                "https://api.supadata.ai/v1/youtube/transcript", 
                "https://api.supadata.ai/transcript",
                "https://api.supadata.ai/v1/transcript"
            ]
            
            for endpoint in endpoints_to_try:
                try:
                    print(f"üîÑ Trying endpoint: {endpoint}")
                    response = requests.post(
                        endpoint,
                        headers={
                            "Authorization": f"Bearer {api_key}",
                            "Content-Type": "application/json"
                        },
                        json={"url": url},
                        timeout=1000
                    )
                    
                    if response.status_code == 200:
                        data = response.json()
                        transcript = data.get("transcript") or data.get("text") or ""
                        if transcript:
                            print(f"‚úÖ Success with endpoint: {endpoint}")
                            return transcript
                    else:
                        print(f"‚ùå {endpoint}: {response.status_code}")
                        
                except Exception as e:
                    print(f"‚ùå {endpoint} error: {e}")
                    continue
            
            return None
            
        except Exception as e:
            print(f"‚ùå Fallback error: {e}")
            return None

    async def _poll_supadata_job(self, job_id, api_key):
        """Poll for job results when SupaData returns a job ID"""
        poll_url = f"https://api.supadata.ai/v1/transcript/{job_id}"
        headers = {
            "x-api-key": api_key,
            "Accept": "application/json"
        }

        max_attempts = 60  # 5 minutes max
        attempt = 0

        while attempt < max_attempts:
            try:
                response = requests.get(poll_url, headers=headers, timeout=1000)

                if response.status_code == 200:
                    data = response.json()
                    status = data.get("status")

                    if status == "completed":
                        print("‚úÖ Job completed successfully")
                        transcript = self._extract_transcript_text(data)
                        return transcript
                    elif status == "failed":
                        error = data.get("error", "Unknown error")
                        print(f"‚ùå Job failed: {error}")
                        return None
                    elif status in ["queued", "active"]:
                        print(f"üîÑ Job status: {status}, waiting...")
                        await asyncio.sleep(5)  # Wait 5 seconds
                        attempt += 1
                        continue
                    else:
                        print(f"‚ùå Unknown job status: {status}")
                        return None
                else:
                    print(f"‚ùå Job status check failed: {response.status_code}")
                    return None

            except Exception as e:
                print(f"‚ö†Ô∏è Poll attempt {attempt + 1} failed: {e}")
                attempt += 1
                await asyncio.sleep(5)

        print("‚ùå Job polling timeout")
        return None

    def _extract_transcript_text(self, data):
        """Extract transcript text from SupaData response - handle both dict and list"""
        try:
            print(f"üîç Response data type: {type(data)}")
            
            if isinstance(data, list):
                print(f"üìä List response with {len(data)} items")
                # If it's a list of transcript segments, join them
                if data and isinstance(data[0], dict):
                    # List of objects with text/content fields
                    text_parts = []
                    for item in data:
                        text = item.get("text") or item.get("content") or item.get("transcript") or ""
                        if text:
                            text_parts.append(str(text))
                    
                    if text_parts:
                        full_text = " ".join(text_parts)
                        print(f"‚úÖ Combined {len(text_parts)} segments into {len(full_text)} characters")
                        return full_text
                elif data and isinstance(data[0], str):
                    # List of strings
                    full_text = " ".join(data)
                    print(f"‚úÖ Combined {len(data)} string segments")
                    return full_text
            
            elif isinstance(data, dict):
                # Original dict handling
                # Prefer 'content' key if present
                value = data.get("content")
                if value is not None:
                    if isinstance(value, str):
                        print(f"‚úÖ Extracted from dict 'content' (string): {len(value)} characters")
                        return value.strip()
                    if isinstance(value, list):
                        # Flatten list of strings or dict segments into a single string
                        text_parts = []
                        for item in value:
                            if isinstance(item, str):
                                text_parts.append(item)
                            elif isinstance(item, dict):
                                t = item.get("text") or item.get("content") or item.get("transcript") or ""
                                if isinstance(t, list):
                                    nested = self._extract_transcript_text(t)
                                    if nested:
                                        text_parts.append(nested)
                                elif t:
                                    text_parts.append(str(t))
                        if text_parts:
                            full_text = " ".join(text_parts)
                            print(f"‚úÖ Combined 'content' list into {len(full_text)} characters")
                            return full_text
                
                # Fallback to other common keys
                for key in ("text", "transcript", "data"):
                    if key in data:
                        val = data[key]
                        if isinstance(val, str):
                            print(f"‚úÖ Extracted from dict '{key}' (string): {len(val)} characters")
                            return val.strip()
                        elif isinstance(val, list):
                            # Recursive handling for nested lists
                            return self._extract_transcript_text(val)
                
                print("‚ÑπÔ∏è Dict present but did not contain extractable string content")
                return None
            
            elif isinstance(data, str):
                # Direct string response
                print(f"‚úÖ Direct string response: {len(data)} characters")
                return data.strip()
            
            print("‚ùå No transcript content found in response")
            print(f"Response preview: {str(data)[:200]}...")
            return None
            
        except Exception as e:
            print(f"‚ùå Extract transcript error: {e}")
            print(f"Data type: {type(data)}")
            return None


    async def process_with_deepseek(self, transcript, chat_id, context, custom_prompt=None):
        """Process transcript through DeepSeek API in chunks"""
        try:
            api_key = os.getenv("DEEPSEEK_API_KEY")  # Set this environment variable
            prompt = custom_prompt if custom_prompt else self.deepseek_prompt
            
            if not api_key:
                print("‚ùå DEEPSEEK_API_KEY not set")
                return None
            
            # Split transcript into smaller chunks to reduce API timeouts (configurable)
            try:
                chunk_size = int(os.getenv("DEEPSEEK_CHUNK_SIZE", 7000))
            except Exception:
                chunk_size = 7000
            chunks = self.split_text_into_chunks(transcript, chunk_size)
            processed_chunks = []
            
            await context.bot.send_message(chat_id, f"ü§ñ Processing {len(chunks)} chunks with DeepSeek...")
            
            for i, chunk in enumerate(chunks):
                await context.bot.send_message(chat_id, f"üîÑ DeepSeek chunk {i+1}/{len(chunks)}")

                # Robust DeepSeek API call with retries
                try:
                    max_retries = int(os.getenv("DEEPSEEK_MAX_RETRIES", 3))
                except Exception:
                    max_retries = 3
                try:
                    timeout_seconds = int(os.getenv("DEEPSEEK_TIMEOUT", 1000))
                except Exception:
                    timeout_seconds = 1000
                try:
                    backoff_seconds = int(os.getenv("DEEPSEEK_BACKOFF", 5))
                except Exception:
                    backoff_seconds = 5
                processed_text = None

                for attempt in range(1, max_retries + 1):
                    try:
                        response = requests.post(
                            "https://api.deepseek.com/v1/chat/completions",
                            headers={
                                "Authorization": f"Bearer {api_key}",
                                "Content-Type": "application/json"
                            },
                            json={
                                "model": "deepseek-chat",
                                "messages": [
                                    {"role": "system", "content": prompt},
                                    {"role": "user", "content": chunk}
                                ],
                                "temperature": 0.7
                            },
                            timeout=timeout_seconds
                        )

                        if response.status_code == 200:
                            result = response.json()
                            processed_text = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                            break
                        elif response.status_code == 429:
                            # Rate limited - respect Retry-After if present
                            retry_after = response.headers.get("Retry-After")
                            wait_time = int(retry_after) if retry_after and retry_after.isdigit() else backoff_seconds * attempt
                            print(f"‚ö†Ô∏è DeepSeek rate limited (429) on chunk {i+1}, waiting {wait_time}s and retrying ({attempt}/{max_retries})")
                            await asyncio.sleep(wait_time)
                            continue
                        else:
                            print(f"DeepSeek API error for chunk {i+1}: {response.status_code} - {response.text[:200]}")
                            # Backoff and retry for server errors
                            if 500 <= response.status_code < 600 and attempt < max_retries:
                                await asyncio.sleep(backoff_seconds * attempt)
                                continue
                            break
                    except requests.Timeout:
                        print(f"‚è±Ô∏è DeepSeek timeout on chunk {i+1}, attempt {attempt}/{max_retries}")
                        if attempt < max_retries:
                            await asyncio.sleep(backoff_seconds * attempt)
                            continue
                    except requests.RequestException as e:
                        print(f"üåê DeepSeek request error on chunk {i+1}, attempt {attempt}/{max_retries}: {e}")
                        if attempt < max_retries:
                            await asyncio.sleep(backoff_seconds * attempt)
                            continue
                    except Exception as e:
                        print(f"Unexpected DeepSeek error on chunk {i+1}: {e}")
                        break

                if processed_text is None:
                    # Use original if API fails after retries
                    processed_text = chunk
                processed_chunks.append(processed_text)
                # Small delay between chunks to avoid bursts / rate limiting
                await asyncio.sleep(float(os.getenv("DEEPSEEK_INTER_CHUNK_SLEEP", 0.5)))
            
            return " ".join(processed_chunks)
            
        except Exception as e:
            print(f"DeepSeek processing error: {e}")
            return None

    async def process_with_openrouter(self, transcript, chat_id, context, custom_prompt=None):
        """Process transcript through OpenRouter API in chunks"""
        try:
            api_key = os.getenv("OPENROUTER_API_KEY")
            prompt = custom_prompt if custom_prompt else self.youtube_transcript_prompt

            print(f"üîç [OPENROUTER] Checking API key...")
            print(f"üîç [OPENROUTER] API key found: {bool(api_key)}")

            if not api_key:
                error_msg = "‚ùå OPENROUTER_API_KEY not set in .env file"
                print(f"‚ùå [OPENROUTER] {error_msg}")
                await context.bot.send_message(chat_id, error_msg)
                return None

            # Split transcript into smaller chunks
            try:
                chunk_size = int(os.getenv("OPENROUTER_CHUNK_SIZE", 7000))
            except Exception:
                chunk_size = 7000
            chunks = self.split_text_into_chunks(transcript, chunk_size)
            processed_chunks = []

            await context.bot.send_message(chat_id, f"ü§ñ Processing {len(chunks)} chunks with OpenRouter...")

            for i, chunk in enumerate(chunks):
                await context.bot.send_message(chat_id, f"üîÑ OpenRouter chunk {i+1}/{len(chunks)}")

                # OpenRouter API call with retries
                try:
                    max_retries = 3
                    timeout_seconds = 1000
                    backoff_seconds = 5
                except Exception:
                    max_retries = 3
                    timeout_seconds = 1000
                    backoff_seconds = 5

                processed_text = None

                for attempt in range(1, max_retries + 1):
                    try:
                        print(f"üîÑ [OPENROUTER] Making API request for chunk {i+1}...")
                        response = requests.post(
                            "https://openrouter.ai/api/v1/chat/completions",
                            headers={
                                "Authorization": f"Bearer {api_key}",
                                "Content-Type": "application/json",
                                "HTTP-Referer": "https://github.com/anthropics/claude-code",
                                "X-Title": "F5-TTS Bot"
                            },
                            json={
                                "model": self.openrouter_model,
                                "messages": [
                                    {"role": "system", "content": prompt},
                                    {"role": "user", "content": chunk}
                                ],
                                "temperature": 0.7
                            },
                            timeout=timeout_seconds
                        )

                        print(f"üìä [OPENROUTER] Response status: {response.status_code}")

                        if response.status_code == 200:
                            result = response.json()
                            processed_text = result['choices'][0]['message']['content'].strip()
                            print(f"‚úÖ [OPENROUTER] Chunk {i+1} processed successfully")
                            break
                        elif response.status_code == 429:
                            # Rate limited
                            retry_after = response.headers.get("Retry-After")
                            wait_time = int(retry_after) if retry_after and retry_after.isdigit() else backoff_seconds * attempt
                            print(f"‚ö†Ô∏è [OPENROUTER] Rate limited (429) on chunk {i+1}, waiting {wait_time}s")
                            await asyncio.sleep(wait_time)
                            continue
                        else:
                            print(f"‚ùå [OPENROUTER] API error for chunk {i+1}: {response.status_code} - {response.text[:200]}")
                            if 500 <= response.status_code < 600 and attempt < max_retries:
                                await asyncio.sleep(backoff_seconds * attempt)
                                continue
                            break
                    except requests.Timeout:
                        print(f"‚è±Ô∏è [OPENROUTER] Timeout on chunk {i+1}, attempt {attempt}/{max_retries}")
                        if attempt < max_retries:
                            await asyncio.sleep(backoff_seconds * attempt)
                            continue
                    except requests.RequestException as e:
                        print(f"üåê [OPENROUTER] Request error on chunk {i+1}, attempt {attempt}/{max_retries}: {e}")
                        if attempt < max_retries:
                            await asyncio.sleep(backoff_seconds * attempt)
                            continue
                    except Exception as e:
                        print(f"‚ùå [OPENROUTER] Unexpected error on chunk {i+1}: {e}")
                        break

                if processed_text is None:
                    print(f"‚ö†Ô∏è [OPENROUTER] Chunk {i+1} processing failed, using original")
                    processed_text = chunk
                processed_chunks.append(processed_text)
                # Small delay between chunks
                await asyncio.sleep(0.5)

            return " ".join(processed_chunks)

        except Exception as e:
            print(f"‚ùå [OPENROUTER] Processing error: {e}")
            return None

    async def process_two_sentences_with_prompt(self, two_sentences, prompt_text, chat_id, context):
        """Process exactly 2 sentences with custom prompt via DeepSeek with stop support"""
        try:
            api_key = os.getenv("DEEPSEEK_API_KEY")
            if not api_key:
                print("‚ùå DEEPSEEK_API_KEY not set")
                return None
            
            full_prompt = f"{prompt_text}\n\nHere is the script:\n{two_sentences}"
            
            # Make request in a thread to allow stop checking
            import concurrent.futures
            
            def make_deepseek_request():
                try:
                    response = requests.post(
                        "https://api.deepseek.com/v1/chat/completions",
                        headers={
                            "Authorization": f"Bearer {api_key}",
                            "Content-Type": "application/json"
                        },
                        json={
                            "model": "deepseek-chat",
                            "messages": [
                                {"role": "user", "content": full_prompt}
                            ],
                            "temperature": 0.7
                        },
                        timeout=120
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        return result.get("choices", [{}])[0].get("message", {}).get("content", "")
                    else:
                        return None
                except Exception as e:
                    print(f"DeepSeek request error: {e}")
                    return None
            
            # Run in executor with periodic stop checks
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(make_deepseek_request)
                
                # Check every 0.5 seconds if stop was requested
                while not future.done():
                    if self.stop_requested:
                        print("üõë Stop requested during DeepSeek call")
                        future.cancel()
                        return None
                    await asyncio.sleep(0.5)
                
                return future.result()
            
        except Exception as e:
            print(f"Process two sentences error: {e}")
            return None

    async def generate_title_with_deepseek(self, prompt, content, chat_id, context):
        """Generate title using DeepSeek API with given prompt and content"""
        try:
            api_key = os.getenv("DEEPSEEK_API_KEY")

            # Debug logging
            print(f"üîç [TITLE GEN] Checking API key...")
            print(f"üîç [TITLE GEN] API key found: {bool(api_key)}")
            if api_key:
                print(f"üîç [TITLE GEN] API key length: {len(api_key)}")
                print(f"üîç [TITLE GEN] API key starts with: {api_key[:10]}...")

            if not api_key:
                error_msg = "‚ùå DeepSeek API key not configured in .env file"
                print(f"‚ùå [TITLE GEN] {error_msg}")
                await context.bot.send_message(chat_id, error_msg)
                return None

            # Combine prompt with content
            full_prompt = f"{prompt}\n\n{content}"
            print(f"‚úÖ [TITLE GEN] Full prompt length: {len(full_prompt)} chars")

            # Send processing message
            await context.bot.send_message(chat_id, "ü§ñ Generating title with DeepSeek AI...")

            # Make API call
            try:
                print(f"üîÑ [TITLE GEN] Making API request to DeepSeek...")
                response = requests.post(
                    "https://api.deepseek.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "deepseek-chat",
                        "messages": [
                            {"role": "user", "content": full_prompt}
                        ],
                        "temperature": 0.7
                    },
                    timeout=60
                )

                print(f"üìä [TITLE GEN] Response status: {response.status_code}")

                if response.status_code == 200:
                    result = response.json()
                    title = result['choices'][0]['message']['content'].strip()
                    print(f"‚úÖ [TITLE GEN] Title generated: {title}")
                    return title
                else:
                    error_msg = f"DeepSeek API error: {response.status_code} - {response.text[:200]}"
                    print(f"‚ùå [TITLE GEN] {error_msg}")
                    await context.bot.send_message(chat_id, f"‚ùå DeepSeek API error: {response.status_code}\n\nDetails: {response.text[:100]}")
                    return None

            except requests.Timeout:
                error_msg = "DeepSeek request timed out"
                print(f"‚è±Ô∏è [TITLE GEN] {error_msg}")
                await context.bot.send_message(chat_id, f"‚ùå {error_msg}")
                return None
            except Exception as e:
                error_msg = f"DeepSeek request error: {str(e)}"
                print(f"‚ùå [TITLE GEN] {error_msg}")
                await context.bot.send_message(chat_id, f"‚ùå Error: {str(e)}")
                return None

        except Exception as e:
            error_msg = f"Title generation error: {str(e)}"
            print(f"‚ùå [TITLE GEN] {error_msg}")
            return None

    def extract_continuation_paragraph(self, deepseek_output):
        """
        Extract only the continuation paragraph (10 sentences) from DeepSeek output.
        """
        try:
            print(f"üìù Raw output length: {len(deepseek_output)} chars")
            
            # Remove any markdown formatting
            text = deepseek_output.replace('**', '').replace('*', '').strip()
            
            # Split into sentences
            sentences = re.split(r'(?<=[.!?])\s+', text)
            
            # Filter out any metadata/labels
            clean_sentences = []
            for sent in sentences:
                sent = sent.strip()
                # Skip sentences that are labels or examples
                if any(skip in sent.lower() for skip in [
                    'original sentence',
                    'rewritten sentences',
                    'continuation sentences',
                    'step 1',
                    'step 2',
                    'example',
                    'here is',
                    'based on'
                ]):
                    continue
                
                # Skip very short sentences (likely labels)
                if len(sent) < 20:
                    continue
                    
                clean_sentences.append(sent)
            
            # The continuation paragraph should be the last 10 sentences
            if len(clean_sentences) >= 10:
                continuation = ' '.join(clean_sentences[-10:])
                print(f"‚úÖ Extracted {len(clean_sentences[-10:])} continuation sentences")
                return continuation
            
            # If we don't have enough, try to get all clean sentences after first 2
            elif len(clean_sentences) > 2:
                continuation = ' '.join(clean_sentences[2:])
                print(f"‚ö†Ô∏è Only found {len(clean_sentences[2:])} sentences, using all after first 2")
                return continuation
            
            # Fallback: return all clean text
            print("‚ö†Ô∏è Could not extract properly, using all clean text")
            return ' '.join(clean_sentences) if clean_sentences else deepseek_output
            
        except Exception as e:
            print(f"‚ùå Extract error: {e}")
            return deepseek_output.strip()

    async def cleanup_processing_files(self, exclude_scripts=False):
        """Clean up processing files but keep audio"""
        try:
            # Clean scripts directory only if not excluded
            if not exclude_scripts:
                for file_path in glob.glob(os.path.join(SCRIPTS_DIR, "*")):
                    try:
                        os.remove(file_path)
                    except:
                        pass
            
            print("‚úÖ Cleaned processing files")
        except Exception as e:
            print(f"Cleanup error: {e}")

    def init_f5_tts(self):
        """F5-TTS model initialize kariye"""
        try:
            print("üîÑ Loading F5-TTS API...")
            from f5_tts.api import F5TTS
            
            self.f5_model = F5TTS()
            print("‚úÖ F5-TTS API loaded successfully!")
            
        except Exception as e:
            print(f"‚ùå F5-TTS initialization error: {e}")
            self.f5_model = None
    
    def load_manual_reference(self):
        """Manual reference audio load kariye"""
        try:
            # Reference folder mein files check kariye
            audio_files = []
            for ext in ['*.wav', '*.mp3', '*.ogg', '*.m4a']:
                audio_files.extend(glob.glob(os.path.join(REFERENCE_DIR, ext)))
            
            if audio_files:
                # Pehli file use kariye
                new_reference = audio_files[0]
                # If already transcribed for this file, skip
                if getattr(self, 'reference_audio', None) == new_reference and getattr(self, 'reference_text', None):
                    print(f"‚úÖ Reference cached: {new_reference}")
                    return
                self.reference_audio = new_reference
                print(f"‚úÖ Reference audio: {self.reference_audio}")
                
                # Whisper load kariye aur text extract kariye (CPU)
                print("üîÑ Loading Whisper for reference text (CPU)...")
                self.whisper_model = whisper.load_model("base", device="cpu")
                
                result = self.whisper_model.transcribe(self.reference_audio)
                self.reference_text = result["text"].strip()
                print(f"‚úÖ Reference text: {self.reference_text[:100]}...")
            else:
                print("‚ö†Ô∏è No reference audio found in reference folder")
                
        except Exception as e:
            print(f"‚ùå Reference load error: {e}")
    
    async def handle_audio_reference(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle new reference audio uploads"""
        try:
            user_id = update.effective_user.id if update.effective_user else "Channel/Anonymous"
            chat_id = update.effective_chat.id
            is_channel = update.message and update.message.chat.type == "channel"

            print(f"üéµ Audio handler triggered by user: {user_id}, chat: {chat_id}")

            # Helper function to send messages (works for both channels and private chats)
            async def send_message(text):
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=text)
                else:
                    await update.message.reply_text(text)

            if update.message.audio or update.message.voice:
                await send_message("üéµ Processing new reference audio...")

                # Download the audio file
                if update.message.audio:
                    file = await context.bot.get_file(update.message.audio.file_id)
                    filename = f"ref_{int(time.time())}.mp3"
                    print(f"üìÅ Processing audio file: {filename}")
                else:  # voice message
                    file = await context.bot.get_file(update.message.voice.file_id)
                    filename = f"ref_{int(time.time())}.ogg"
                    print(f"üé§ Processing voice message: {filename}")

                file_path = os.path.join(REFERENCE_DIR, filename)
                await file.download_to_drive(file_path)
                print(f"‚úÖ Downloaded to: {file_path}")

                # Extract text with Whisper
                if not self.whisper_model:
                    print("üîÑ Loading Whisper model...")
                    self.whisper_model = whisper.load_model("base", device="cpu")

                print("üîÑ Transcribing audio...")
                result = self.whisper_model.transcribe(file_path)
                new_ref_text = result["text"].strip()
                print(f"üìù Extracted: {new_ref_text[:50]}...")

                # Update bot's reference
                old_ref = os.path.basename(self.reference_audio) if self.reference_audio else "None"
                self.reference_audio = file_path
                self.reference_text = new_ref_text

                print(f"‚úÖ Reference updated from {old_ref} to {filename}")

                await send_message(
                    f"‚úÖ Reference audio updated!\n\n"
                    f"üîÑ Previous: {old_ref}\n"
                    f"üéµ New: {filename}\n\n"
                    f"üìù Extracted text: {new_ref_text[:150]}{'...' if len(new_ref_text) > 150 else ''}\n\n"
                    f"Use /ref_back to revert to default reference."
                )

            else:
                print("‚ö†Ô∏è No audio or voice in message")

        except Exception as e:
            error_msg = f"‚ùå Reference update error: {str(e)}"
            print(error_msg)
            # Safe error message sending
            try:
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=error_msg)
                else:
                    await update.message.reply_text(error_msg)
            except:
                print(f"Could not send error message: {error_msg}")

    async def ref_back_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Revert to default reference audio"""
        try:
            # Load original reference
            self.load_manual_reference()
            
            ref_name = os.path.basename(self.reference_audio) if self.reference_audio else "None"
            await update.message.reply_text(
                f"üîÑ Reverted to default reference: {ref_name}\n\n"
                f"üìù Text: {self.reference_text[:100]}{'...' if len(self.reference_text) > 100 else ''}"
            )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Revert error: {str(e)}")

    async def set_prompt_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Change DeepSeek prompt via Telegram"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.deepseek_prompt = new_prompt

                # Save configuration to file
                self.save_config()

                # Create a button to return to settings
                keyboard = [[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]]
                reply_markup = InlineKeyboardMarkup(keyboard)

                await update.message.reply_text(
                    f"‚úÖ DeepSeek prompt updated and saved!\n\n"
                    f"üìù New prompt: {new_prompt}",
                    reply_markup=reply_markup
                )
            else:
                # Create a button to return to settings
                keyboard = [[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]]
                reply_markup = InlineKeyboardMarkup(keyboard)

                await update.message.reply_text(
                    f"üìù Current prompt: {self.deepseek_prompt}\n\n"
                    f"üí° Usage: /set_prompt Your new prompt here",
                    reply_markup=reply_markup
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Prompt update error: {str(e)}")

    async def set_youtube_prompt_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Change YouTube Transcript Processing prompt via Telegram"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.youtube_transcript_prompt = new_prompt

                # Save configuration to file
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ YouTube Transcript prompt updated and saved!\n\n"
                    f"üìù New prompt: {new_prompt}"
                )
            else:
                await update.message.reply_text(
                    f"üìù Current YouTube Transcript prompt:\n{self.youtube_transcript_prompt}\n\n"
                    f"üí° Usage: /set_youtube_prompt Your new prompt here\n\n"
                    f"Example:\n/set_youtube_prompt Rewrite this transcript for engaging TTS audio"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå YouTube prompt update error: {str(e)}")

    async def start_processing_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Skip batch timer and start processing immediately"""
        try:
            if not self.batch_mode:
                await update.message.reply_text(
                    "‚ÑπÔ∏è No batch collection in progress.\n\n"
                    f"üìä Queue: {len(self.processing_queue)} files\n"
                    f"‚è≥ Processing status: {'Active' if self.is_processing else 'Idle'}"
                )
                return

            queue_size = len(self.processing_queue)

            if queue_size == 0:
                await update.message.reply_text("‚ùå Queue is empty!")
                return

            # Cancel timer and start immediately
            await update.message.reply_text(
                f"‚ö° **STARTING IMMEDIATELY**\n\n"
                f"üìä Files in queue: {queue_size}\n"
                f"‚è±Ô∏è Batch timer skipped!\n\n"
                f"Processing will start now..."
            )

            # Stop batch mode
            self.batch_mode = False
            self.queue_start_time = None

            # Start processing
            chat_id = update.effective_chat.id
            asyncio.create_task(self.process_queue(context))

        except Exception as e:
            await update.message.reply_text(f"‚ùå Error: {str(e)}")

    async def update_ytdlp_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Update yt-dlp to latest version"""
        try:
            await update.message.reply_text("üîÑ Updating yt-dlp to latest version...\nThis may take 10-30 seconds.")

            # Run pip update command
            result = subprocess.run(
                ["pip", "install", "-U", "yt-dlp"],
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode == 0:
                # Get version
                version_result = subprocess.run(
                    ["yt-dlp", "--version"],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                version = version_result.stdout.strip() if version_result.returncode == 0 else "unknown"

                await update.message.reply_text(
                    f"‚úÖ yt-dlp updated successfully!\n\n"
                    f"üì¶ Version: {version}\n\n"
                    f"üé• You can now try downloading YouTube videos again.\n"
                    f"If still getting 403 errors, wait 2-5 minutes."
                )
            else:
                error_msg = result.stderr[:500] if result.stderr else "Unknown error"
                await update.message.reply_text(
                    f"‚ùå Update failed!\n\n"
                    f"Error: {error_msg}\n\n"
                    f"üí° Try manually:\n"
                    f"`pip install -U yt-dlp`"
                )
        except subprocess.TimeoutExpired:
            await update.message.reply_text(
                "‚è±Ô∏è Update timed out!\n\n"
                "üí° Try manually:\n"
                "`pip install -U yt-dlp`"
            )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Update error: {str(e)}")

    async def set_openrouter_model_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Change OpenRouter model via Telegram"""
        try:
            if context.args:
                new_model = " ".join(context.args)
                self.openrouter_model = new_model

                # Save configuration to file
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ OpenRouter model updated and saved!\n\n"
                    f"üåê New model: {new_model}\n\n"
                    f"üí° Popular models:\n"
                    f"‚Ä¢ deepseek/deepseek-chat\n"
                    f"‚Ä¢ anthropic/claude-3.5-sonnet\n"
                    f"‚Ä¢ openai/gpt-4-turbo\n"
                    f"‚Ä¢ google/gemini-pro-1.5\n"
                    f"‚Ä¢ meta-llama/llama-3.1-70b-instruct"
                )
            else:
                await update.message.reply_text(
                    f"üåê Current OpenRouter model:\n{self.openrouter_model}\n\n"
                    f"üí° Usage: /set_openrouter_model model_name\n\n"
                    f"Examples:\n"
                    f"/set_openrouter_model deepseek/deepseek-chat\n"
                    f"/set_openrouter_model anthropic/claude-3.5-sonnet\n"
                    f"/set_openrouter_model openai/gpt-4-turbo\n\n"
                    f"Find more models at: https://openrouter.ai/models"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå OpenRouter model update error: {str(e)}")

    async def set_ffmpeg_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Change FFmpeg audio filter via Telegram"""
        try:
            chat_id = update.effective_chat.id

            if context.args:
                raw_input = " ".join(context.args)

                # Smart parsing - extract filter from full ffmpeg command if needed
                new_filter = self._extract_ffmpeg_filter(raw_input)

                if not new_filter:
                    response = (
                        "‚ùå Could not extract filter!\n\n"
                        "Please provide either:\n"
                        "1. Just the filter: afftdn=nr=12,highpass=f=80\n"
                        "2. Full command: ffmpeg -i input.wav -af \"filter\" output.wav\n\n"
                        "Current filter unchanged."
                    )
                    await context.bot.send_message(chat_id=chat_id, text=response)
                    return

                self.ffmpeg_filter = new_filter

                # Save configuration to file
                self.save_config()

                response = (
                    f"‚úÖ FFmpeg filter updated and saved!\n\n"
                    f"üéöÔ∏è New filter: {new_filter}\n\n"
                    f"This will be applied to all enhanced audio from now on."
                )
                await context.bot.send_message(chat_id=chat_id, text=response)
            else:
                response = (
                    f"üéöÔ∏è Current FFmpeg filter:\n{self.ffmpeg_filter}\n\n"
                    f"üí° Usage: /set_ffmpeg your_filter_here\n\n"
                    f"Example:\n/set_ffmpeg afftdn=nr=12:nf=-25,highpass=f=80,lowpass=f=10000"
                )
                await context.bot.send_message(chat_id=chat_id, text=response)
        except Exception as e:
            await context.bot.send_message(chat_id=update.effective_chat.id, text=f"‚ùå FFmpeg filter update error: {str(e)}")

    async def set_chunk_size_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Change audio generation chunk size via Telegram"""
        try:
            chat_id = update.effective_chat.id

            if context.args:
                try:
                    new_size = int(context.args[0])

                    if new_size < 100 or new_size > 5000:
                        response = (
                            "‚ùå Invalid chunk size!\n\n"
                            "Must be between 100 and 5000 characters.\n\n"
                            "Recommended values:\n"
                            "‚Ä¢ 500 (default) - Best quality, slower\n"
                            "‚Ä¢ 1000 - Good quality, faster\n"
                            "‚Ä¢ 1500 - Decent quality, fast\n"
                            "‚Ä¢ 2000+ - Lower quality, very fast (RTX 4090 recommended)"
                        )
                        await context.bot.send_message(chat_id=chat_id, text=response)
                        return

                    old_size = self.chunk_size
                    self.chunk_size = new_size

                    # Save configuration to file
                    self.save_config()

                    response = (
                        f"‚úÖ Chunk size updated and saved!\n\n"
                        f"üìä Old: {old_size} chars\n"
                        f"üìä New: {new_size} chars\n\n"
                        f"‚ö†Ô∏è Warning:\n"
                        f"Higher chunk size = Faster processing but LOWER audio quality!\n\n"
                        f"Best for:\n"
                        f"‚Ä¢ 500-1000: High quality (recommended)\n"
                        f"‚Ä¢ 1500-2000: Balanced (RTX 3090/4080)\n"
                        f"‚Ä¢ 2000+: Speed priority (RTX 4090)"
                    )
                    await context.bot.send_message(chat_id=chat_id, text=response)
                except ValueError:
                    await context.bot.send_message(chat_id=chat_id, text="‚ùå Please provide a valid number!\n\nExample: /set_chunk_size 1000")
            else:
                response = (
                    f"üìä Current chunk size: {self.chunk_size} characters\n\n"
                    f"üí° Usage: /set_chunk_size <number>\n\n"
                    f"Examples:\n"
                    f"‚Ä¢ /set_chunk_size 500 (best quality)\n"
                    f"‚Ä¢ /set_chunk_size 1000 (good quality)\n"
                    f"‚Ä¢ /set_chunk_size 2000 (fast, RTX 4090)\n\n"
                    f"‚ö†Ô∏è Higher values = Faster but lower quality!"
                )
                await context.bot.send_message(chat_id=chat_id, text=response)
        except Exception as e:
            await context.bot.send_message(chat_id=update.effective_chat.id, text=f"‚ùå Chunk size update error: {str(e)}")

    def _extract_ffmpeg_filter(self, raw_input):
        """Extract filter string from FFmpeg command or return as-is if already a filter"""
        try:
            # Remove extra spaces
            raw_input = raw_input.strip()

            # Check if it's a full FFmpeg command (starts with 'ffmpeg')
            if raw_input.lower().startswith('ffmpeg'):
                # Look for -af or -filter:a flag
                import re

                # Pattern 1: -af "filter" or -af 'filter'
                match = re.search(r'-af\s+["\'](.+?)["\']', raw_input)
                if match:
                    return match.group(1)

                # Pattern 2: -af filter (without quotes, until next flag or end)
                # Match filter parts (contains = or , but not .wav/.mp3/.mp4 filenames)
                match = re.search(r'-af\s+([a-zA-Z0-9_=:,\-]+)(?:\s|$)', raw_input)
                if match:
                    return match.group(1).strip()

                # Pattern 3: -filter:a "filter" or -filter:a 'filter'
                match = re.search(r'-filter:a\s+["\'](.+?)["\']', raw_input)
                if match:
                    return match.group(1)

                # Pattern 4: -filter:a filter
                match = re.search(r'-filter:a\s+([a-zA-Z0-9_=:,\-]+)(?:\s|$)', raw_input)
                if match:
                    return match.group(1).strip()

                # Could not extract filter
                return None
            else:
                # Not a full command, assume it's already a filter
                # Remove quotes if present
                if raw_input.startswith('"') and raw_input.endswith('"'):
                    raw_input = raw_input[1:-1]
                elif raw_input.startswith("'") and raw_input.endswith("'"):
                    raw_input = raw_input[1:-1]

                return raw_input

        except Exception as e:
            print(f"‚ùå Filter extraction error: {e}")
            return None

    @staticmethod
    def _extract_ffmpeg_filter_static(raw_input):
        """Static version of filter extractor for use during config loading"""
        try:
            import re
            raw_input = raw_input.strip()

            # Check if it's a full FFmpeg command (starts with 'ffmpeg')
            if raw_input.lower().startswith('ffmpeg'):
                # Pattern 1: -af "filter" or -af 'filter'
                match = re.search(r'-af\s+["\'](.+?)["\']', raw_input)
                if match:
                    return match.group(1)

                # Pattern 2: -af filter (without quotes)
                match = re.search(r'-af\s+([a-zA-Z0-9_=:,\-]+)(?:\s|$)', raw_input)
                if match:
                    return match.group(1).strip()

                # Pattern 3: -filter:a "filter"
                match = re.search(r'-filter:a\s+["\'](.+?)["\']', raw_input)
                if match:
                    return match.group(1)

                # Pattern 4: -filter:a filter
                match = re.search(r'-filter:a\s+([a-zA-Z0-9_=:,\-]+)(?:\s|$)', raw_input)
                if match:
                    return match.group(1).strip()

                # Could not extract, return default
                print(f"‚ö†Ô∏è Could not extract filter from command, using default")
                return 'afftdn=nr=12:nf=-25,highpass=f=80,lowpass=f=10000,equalizer=f=6000:t=h:width=2000:g=-6'
            else:
                # Not a full command, remove quotes if present
                if raw_input.startswith('"') and raw_input.endswith('"'):
                    raw_input = raw_input[1:-1]
                elif raw_input.startswith("'") and raw_input.endswith("'"):
                    raw_input = raw_input[1:-1]
                return raw_input

        except Exception as e:
            print(f"‚ùå Static filter extraction error: {e}, using default")
            return 'afftdn=nr=12:nf=-25,highpass=f=80,lowpass=f=10000,equalizer=f=6000:t=h:width=2000:g=-6'

    async def set_jesus_prompt_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Set Jesus image prompt"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.jesus_prompt = new_prompt
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ Jesus prompt updated and saved!\n\n"
                    f"‚úùÔ∏è New prompt: {new_prompt}"
                )
            else:
                await update.message.reply_text(
                    f"‚úùÔ∏è Current Jesus prompt:\n{self.jesus_prompt}\n\n"
                    f"üí° Usage: /set_jesus_prompt your_prompt_here\n\n"
                    f"Example:\n/set_jesus_prompt A serene image of Jesus with divine light"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Jesus prompt update error: {str(e)}")

    async def set_nature_prompt_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Set Nature image prompt"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.nature_prompt = new_prompt
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ Nature prompt updated and saved!\n\n"
                    f"üåø New prompt: {new_prompt}"
                )
            else:
                await update.message.reply_text(
                    f"üåø Current Nature prompt:\n{self.nature_prompt}\n\n"
                    f"üí° Usage: /set_nature_prompt your_prompt_here\n\n"
                    f"Example:\n/set_nature_prompt Beautiful nature landscape with mountains and sunset"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Nature prompt update error: {str(e)}")

    async def set_leonardo_url_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Set Leonardo AI URL"""
        try:
            if context.args:
                new_url = " ".join(context.args)
                self.leonardo_url = new_url
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ Leonardo URL updated and saved!\n\n"
                    f"üé® New URL: {new_url}"
                )
            else:
                await update.message.reply_text(
                    f"üé® Current Leonardo URL:\n{self.leonardo_url}\n\n"
                    f"üí° Usage: /set_leonardo_url your_url_here\n\n"
                    f"Example:\n/set_leonardo_url https://leonardo.ai"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Leonardo URL update error: {str(e)}")

    async def set_title_prompt1_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Set Title Generation Prompt 1 (Initial)"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.title_prompt_1 = new_prompt
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ Title Prompt 1 (Initial) updated and saved!\n\n"
                    f"üìù New prompt: {new_prompt}"
                )
            else:
                await update.message.reply_text(
                    f"üìù Current Title Prompt 1 (Initial):\n{self.title_prompt_1}\n\n"
                    f"üí° Usage: /set_title_prompt1 your_prompt_here\n\n"
                    f"Example:\n/set_title_prompt1 Generate a catchy title for this video script:"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Title Prompt 1 update error: {str(e)}")

    async def set_title_prompt2_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Set Title Generation Prompt 2 (Refine)"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.title_prompt_2 = new_prompt
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ Title Prompt 2 (Refine) updated and saved!\n\n"
                    f"üìù New prompt: {new_prompt}"
                )
            else:
                await update.message.reply_text(
                    f"üìù Current Title Prompt 2 (Refine):\n{self.title_prompt_2}\n\n"
                    f"üí° Usage: /set_title_prompt2 your_prompt_here\n\n"
                    f"Example:\n/set_title_prompt2 Refine this title to make it more engaging:"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Title Prompt 2 update error: {str(e)}")

    async def set_title_prompt3_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Set Title Generation Prompt 3 (Final Polish)"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.title_prompt_3 = new_prompt
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ Title Prompt 3 (Final Polish) updated and saved!\n\n"
                    f"üìù New prompt: {new_prompt}"
                )
            else:
                await update.message.reply_text(
                    f"üìù Current Title Prompt 3 (Final Polish):\n{self.title_prompt_3}\n\n"
                    f"üí° Usage: /set_title_prompt3 your_prompt_here\n\n"
                    f"Example:\n/set_title_prompt3 Polish this title to perfection:"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Title Prompt 3 update error: {str(e)}")

    async def set_title_prompt_10more_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Set Title Generation Prompt for 10 More Titles"""
        try:
            if context.args:
                new_prompt = " ".join(context.args)
                self.title_prompt_10_more = new_prompt
                self.save_config()

                await update.message.reply_text(
                    f"‚úÖ Title Prompt (10 More) updated and saved!\n\n"
                    f"üìù New prompt: {new_prompt}"
                )
            else:
                await update.message.reply_text(
                    f"üìù Current Title Prompt (10 More):\n{self.title_prompt_10_more}\n\n"
                    f"üí° Usage: /set_title_prompt_10more your_prompt_here\n\n"
                    f"Example:\n/set_title_prompt_10more Generate 10 different catchy titles for this script:"
                )
        except Exception as e:
            await update.message.reply_text(f"‚ùå Title Prompt (10 More) update error: {str(e)}")

    async def ref_status_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Show current reference status with buttons"""
        ref_name = os.path.basename(self.reference_audio) if self.reference_audio else "None"
        ref_text = self.reference_text[:200] if self.reference_text else "None"
        
        # Create buttons for reference actions
        keyboard = [
            [InlineKeyboardButton("üîÑ Revert to Default", callback_data="ref:back")],
            [InlineKeyboardButton("üéµ Set New Reference", callback_data="settings:ref")],
            [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            f"üéµ Current Reference Status:\n\n"
            f"üìÅ File: {ref_name}\n"
            f"üìù Text: {ref_text}{'...' if len(ref_text) > 200 else ''}\n\n"
            f"Choose an action:",
            reply_markup=reply_markup
        )

    async def set_ref_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Command to set new reference - reply to an audio message with /set_ref"""
        try:
            # Check if replying to a message
            if not update.message.reply_to_message:
                await update.message.reply_text(
                    "‚ùå Usage:\n"
                    "1. Send an audio file to the bot\n"
                    "2. Reply to that audio with /set_ref\n\n"
                    "Or use: /set_ref [then forward an audio]"
                )
                return
            
            replied_msg = update.message.reply_to_message
            print(f"üîç Checking replied message for audio/voice...")
            print(f"Has audio: {bool(replied_msg.audio)}")
            print(f"Has voice: {bool(replied_msg.voice)}")
            print(f"Has document: {bool(getattr(replied_msg, 'document', None))}")
            
            # Check for audio, voice, or document
            if replied_msg.audio:
                file = await context.bot.get_file(replied_msg.audio.file_id)
                filename = f"ref_{int(time.time())}.mp3"
                print(f"üìÅ Processing audio file")
            elif replied_msg.voice:
                file = await context.bot.get_file(replied_msg.voice.file_id)
                filename = f"ref_{int(time.time())}.ogg"
                print(f"üé§ Processing voice message")
            elif getattr(replied_msg, 'document', None) and replied_msg.document.mime_type and replied_msg.document.mime_type.startswith('audio'):
                file = await context.bot.get_file(replied_msg.document.file_id)
                filename = f"ref_{int(time.time())}.{replied_msg.document.file_name.split('.')[-1]}"
                print(f"üìÑ Processing audio document")
            else:
                await update.message.reply_text("‚ùå The replied message must contain audio, voice, or audio document")
                return
            
            await update.message.reply_text("üéµ Processing new reference audio...")
            
            file_path = os.path.join(REFERENCE_DIR, filename)
            await file.download_to_drive(file_path)
            
            # Extract text with Whisper
            if not self.whisper_model:
                self.whisper_model = whisper.load_model("base", device="cpu")
            
            result = self.whisper_model.transcribe(file_path)
            new_ref_text = result["text"].strip()
            
            # Delete old reference audio to save storage (except default k.wav)
            if self.reference_audio and os.path.exists(self.reference_audio):
                old_filename = os.path.basename(self.reference_audio)
                if not old_filename.startswith('k.') and old_filename != 'k,.wav':  # Keep default
                    try:
                        os.remove(self.reference_audio)
                        print(f"üóëÔ∏è Deleted old reference: {old_filename}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Could not delete old reference: {e}")
            
            # Update bot's reference
            old_ref = os.path.basename(self.reference_audio) if self.reference_audio else "None"
            self.reference_audio = file_path
            self.reference_text = new_ref_text

            # Clear any cached reference data to prevent conflicts
            if hasattr(self.f5_model, '_cached_ref_audio'):
                delattr(self.f5_model, '_cached_ref_audio')
            if hasattr(self.f5_model, '_cached_ref_text'):
                delattr(self.f5_model, '_cached_ref_text')
            
            # Force F5-TTS to reload reference on next generation
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            import gc
            gc.collect()
            
            print(f"‚úÖ Cleared F5-TTS cache for new reference")
            
            await update.message.reply_text(
                f"‚úÖ Reference audio updated!\n\n"
                f"üîÑ Previous: {old_ref}\n"
                f"üéµ New: {filename}\n\n"
                f"üìù Extracted text: {new_ref_text[:150]}{'...' if len(new_ref_text) > 150 else ''}\n\n"
                f"Use /ref_back to revert to default."
            )
            
        except Exception as e:
            error_msg = f"‚ùå Reference update error: {str(e)}"
            print(error_msg)
            await update.message.reply_text(error_msg)


    async def test_audio_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Temporary test handler to debug audio processing"""
        chat_id = update.effective_chat.id
        user_id = update.effective_user.id if update.effective_user else "Channel/Anonymous"
        print(f"üî• TEST: Audio message received from user {user_id}, chat {chat_id}")

        # Send reply only if it's a regular message (not channel post)
        if update.message and update.message.chat.type != "channel":
            await update.message.reply_text("üî• TEST: Audio handler is working!")

        # Now call the actual reference handler
        await self.handle_audio_reference(update, context)

    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Start command - with buttons for settings and processing"""
        try:
            f5_status = "‚úÖ Ready" if self.f5_model else "‚ùå Failed"
            ref_status = "‚úÖ Ready" if self.reference_audio and self.reference_text else "‚ùå Missing"
            
            if self.reference_audio and self.reference_text:
                ref_info = f"üìÅ File: {os.path.basename(self.reference_audio)}\nüìù Text: {self.reference_text[:100]}..."
            else:
                ref_info = "üìÅ Add audio file to reference/ folder and restart"
            
            welcome_text = (
                f"üéâ F5-TTS Bot Ready!\n\n"
                f"üîß F5-TTS Status: {f5_status}\n"
                f"üéµ Reference Status: {ref_status}\n\n"
                f"{ref_info}\n\n"
                f"üìã How to use:\n"
                f"üìÑ Send .txt file with script\n"
                f"üìù Or type text directly\n"
                f"üîó Send YouTube links for transcript processing\n"
                f"üéµ Send audio to change reference"
            )
            
            # Create main menu buttons
            keyboard = [
                [InlineKeyboardButton("‚öôÔ∏è Settings", callback_data="main:settings")],
                [InlineKeyboardButton("üîÑ Processing", callback_data="main:process")],
                [InlineKeyboardButton("üìä Status", callback_data="main:status")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await update.message.reply_text(welcome_text, reply_markup=reply_markup)
            print(f"‚úÖ Start command sent to user: {update.effective_user.id}")
            # Store the welcome text for reuse in callbacks
            self.welcome_text = welcome_text
            
        except Exception as e:
            print(f"‚ùå Start command error: {e}")
            await update.message.reply_text("‚ùå Bot startup error. Please restart.")
        
    async def on_main_menu(self, update, context):
        q = update.callback_query
        try:
            await q.answer()
        except:
            pass

        data = q.data or ""
        chat_id = q.message.chat.id if q and q.message and q.message.chat else None
        
        if data == "main:settings":
            # Settings submenu - ALL COMMANDS ORGANIZED HERE (DeepSeek options removed)
            keyboard = [
                [InlineKeyboardButton("üéµ Reference Audio", callback_data="settings:ref_menu")],
                [InlineKeyboardButton("‚ö° Audio Settings", callback_data="settings:audio_menu")],
                [InlineKeyboardButton("üìÑ Delivery Mode", callback_data="settings:delivery")],
                [InlineKeyboardButton("üîó Completed Files", callback_data="settings:links")],
                [InlineKeyboardButton("‚ö° Power & Control", callback_data="settings:power_menu")],
                [InlineKeyboardButton("üîß Debug Tools", callback_data="settings:debug")],
                [InlineKeyboardButton("üîÑ Pipeline", callback_data="settings:pipeline_menu")],
                [InlineKeyboardButton("üîô Back to Main", callback_data="main:back")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)

            try:
                await q.edit_message_text(
                    "‚öôÔ∏è Settings Menu\n\nüìã All commands organized here for easy access:",
                    reply_markup=reply_markup
                )
            except:
                await q.message.reply_text("‚öôÔ∏è Settings Menu\n\nüìã All commands organized here for easy access:", reply_markup=reply_markup)
        
        elif data == "main:process":
            # Processing options with buttons
            keyboard = [
                [InlineKeyboardButton("üìÑ Upload Text File", callback_data="process:upload_txt")],
                [InlineKeyboardButton("üìù Type Direct Message", callback_data="process:direct_text")],
                [InlineKeyboardButton("üîó Process YouTube Link", callback_data="process:youtube")],
                [InlineKeyboardButton("üîô Back to Main", callback_data="main:back")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await q.edit_message_text(
                "üéµ Processing Mode\n\n"
                "Choose how you want to process content:\n"
                "1. Upload a text file (.txt)\n" 
                "2. Type or paste text directly\n"
                "3. Send a YouTube link to transcribe and process\n\n"
                "Or simply send your content directly in chat!",
                reply_markup=reply_markup
            )
        
        elif data == "main:status":
            # Status info
            queue_count = len(self.processing_queue)
            completed_count = len(self.completed_files)
            
            status_text = (
                f"üìä Bot Status\n\n"
                f"üìù Queue: {queue_count} items\n"
                f"‚úÖ Completed: {completed_count} files\n"
                f"üîÑ Processing: {'Yes' if self.is_processing else 'No'}\n"
                f"‚ö° Speed: {self.audio_speed}x\n"
                f"üîß Quality: {self.audio_quality}\n"
                f"üéµ Reference: {os.path.basename(self.reference_audio) if self.reference_audio else 'Not set'}\n\n"
            )
            
            keyboard = [
                [InlineKeyboardButton("üìÉ View Completed Files", callback_data="status:links")],
                [InlineKeyboardButton("üîô Back to Main", callback_data="main:back")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            try:
                await q.edit_message_text(status_text, reply_markup=reply_markup)
            except:
                await q.message.reply_text(status_text, reply_markup=reply_markup)
        
        elif data == "main:back":
            # Back to main menu - create the same content as start_command but for callback
            try:
                f5_status = "‚úÖ Ready" if self.f5_model else "‚ùå Failed"
                ref_status = "‚úÖ Ready" if self.reference_audio and self.reference_text else "‚ùå Missing"
                
                if self.reference_audio and self.reference_text:
                    ref_info = f"üìÅ File: {os.path.basename(self.reference_audio)}\nüìù Text: {self.reference_text[:100]}..."
                else:
                    ref_info = "üìÅ Add audio file to reference/ folder and restart"
                
                welcome_text = (
                    f"üéâ F5-TTS Bot Ready!\n\n"
                    f"üîß F5-TTS Status: {f5_status}\n"
                    f"üéµ Reference Status: {ref_status}\n\n"
                    f"{ref_info}\n\n"
                    f"üìã How to use:\n"
                    f"üìù Send .txt file with script\n"
                    f"üìù Or type text directly\n"
                    f"üîó Send YouTube links for transcript processing\n"
                    f"üéµ Send audio to change reference"
                )
                
                # Create main menu buttons
                keyboard = [
                    [InlineKeyboardButton("‚öôÔ∏è Settings", callback_data="main:settings")],
                    [InlineKeyboardButton("üîÑ Processing", callback_data="main:process")],
                    [InlineKeyboardButton("üìä Status", callback_data="main:status")]
                ]
                reply_markup = InlineKeyboardMarkup(keyboard)
                
                await q.edit_message_text(welcome_text, reply_markup=reply_markup)
            except Exception as e:
                print(f"‚ùå Back to main error: {e}")
                # If edit fails, try sending a new message
                try:
                    await q.message.reply_text("‚öôÔ∏è Returning to main menu...")
                    await self.start_command(q.message, context)
                except Exception as e2:
                    print(f"‚ùå Fallback error: {e2}")
            
        elif data == "status:links":
            # Show completed files
            await self.links_command(q, context)
    
    async def test_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Test command - quick generation test"""
        try:
            if not self.f5_model:
                await update.message.reply_text("‚ùå F5-TTS not initialized!")
                return
                
            if not self.reference_audio or not self.reference_text:
                await update.message.reply_text("‚ùå Reference audio missing!")
                return
            
            await update.message.reply_text("üß™ Running quick test...")
            
            test_text = "Hello, this is a quick test of the F5-TTS bot."
            success, output_files = await self.generate_audio_f5(test_text)
            if success:
                chat_id = update.effective_chat.id
                self.latest_outputs_by_chat[chat_id] = {"paths": output_files, "links": {}, "filename": "Test", "ts": time.time()}
                await self.send_outputs_by_mode(context, chat_id, output_files, "Test generation", "Test")
            else:
                await update.message.reply_text(f"‚ùå Test failed: {output_files}")
                
        except Exception as e:
            await update.message.reply_text(f"‚ùå Test error: {str(e)}")
    
    async def settings_command(self, update, context):
        # Show main settings menu with buttons - ALL COMMANDS ORGANIZED HERE (DeepSeek options removed)
        chat_id = update.effective_chat.id
        keyboard = [
            [InlineKeyboardButton("üéµ Reference Audio", callback_data="settings:ref_menu")],
            [InlineKeyboardButton("‚ö° Audio Settings", callback_data="settings:audio_menu")],
            [InlineKeyboardButton("üìÑ Delivery Mode", callback_data="settings:delivery")],
            [InlineKeyboardButton("üîó Completed Files", callback_data="settings:links")],
            [InlineKeyboardButton("‚ö° Power & Control", callback_data="settings:power_menu")],
            [InlineKeyboardButton("üîß Debug Tools", callback_data="settings:debug")],
            [InlineKeyboardButton("üîÑ Pipeline", callback_data="settings:pipeline_menu")],
            [InlineKeyboardButton("üîô Back to Main", callback_data="main:back")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await update.message.reply_text(
            "‚öôÔ∏è Settings Menu\n\nüìã All commands organized here for easy access:",
            reply_markup=reply_markup
        )

    async def on_settings(self, update, context):
        q = update.callback_query
        try:
            await q.answer()
        except Exception:
            pass

        chat_id = None
        try:
            chat_id = q.message.chat.id if q and q.message and q.message.chat else None
        except Exception:
            chat_id = None
        if not chat_id:
            chat_id = q.from_user.id if q and q.from_user else None

        data = q.data or ""
        
        # Handle close button
        if data == "settings:close":
            try:
                await q.edit_message_reply_markup(reply_markup=None)
            except Exception:
                pass
            return

        # ====== NEW ORGANIZED MENU HANDLERS ======

        # 1. REFERENCE AUDIO MENU
        elif data == "settings:ref_menu":
            ref_name = os.path.basename(self.reference_audio) if self.reference_audio else "Not set"
            ref_text = self.reference_text[:50] + "..." if self.reference_text and len(self.reference_text) > 50 else self.reference_text or "Not set"

            keyboard = [
                [InlineKeyboardButton("üéµ Set New Reference", callback_data="settings:ref_set")],
                [InlineKeyboardButton("üîÑ Restore Default", callback_data="settings:ref_restore")],
                [InlineKeyboardButton("üìä Check Status", callback_data="settings:ref_status")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            await q.edit_message_text(
                f"üéµ Reference Audio Menu\n\n"
                f"Current Reference:\n"
                f"üìÅ File: {ref_name}\n"
                f"üìù Text: {ref_text}\n\n"
                f"Choose an option:",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )

        elif data == "settings:ref_set":
            await q.edit_message_text(
                "üéµ Set New Reference Audio\n\n"
                "Send a voice message or audio file to set as your new reference.\n\n"
                "Current reference: " + (os.path.basename(self.reference_audio) if self.reference_audio else "Not set"),
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:ref_menu")]])
            )

        elif data == "settings:ref_restore":
            try:
                self.load_manual_reference()
                ref_name = os.path.basename(self.reference_audio) if self.reference_audio else "None"
                await q.edit_message_text(
                    f"‚úÖ Restored to default reference!\n\n"
                    f"üìÅ File: {ref_name}\n"
                    f"üìù Text: {self.reference_text[:100]}{'...' if len(self.reference_text) > 100 else ''}",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:ref_menu")]])
                )
            except Exception as e:
                await q.edit_message_text(
                    f"‚ùå Restore error: {str(e)}",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:ref_menu")]])
                )

        elif data == "settings:ref_status":
            ref_status = "‚úÖ Ready" if self.reference_audio and self.reference_text else "‚ùå Missing"
            ref_name = os.path.basename(self.reference_audio) if self.reference_audio else "Not set"
            ref_text = self.reference_text if self.reference_text else "Not set"

            await q.edit_message_text(
                f"üìä Reference Audio Status\n\n"
                f"Status: {ref_status}\n"
                f"üìÅ File: {ref_name}\n"
                f"üìù Text: {ref_text}",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:ref_menu")]])
            )

        # 2. AUDIO SETTINGS MENU
        elif data == "settings:audio_menu":
            keyboard = [
                [InlineKeyboardButton(f"‚ö° Speed: {self.audio_speed}x", callback_data="settings:speed")],
                [InlineKeyboardButton(f"üîß Quality: {self.audio_quality}", callback_data="settings:quality")],
                [InlineKeyboardButton("üéöÔ∏è FFmpeg Filter", callback_data="settings:ffmpeg")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            await q.edit_message_text(
                "‚ö° Audio Settings Menu\n\n"
                "Configure audio generation settings:",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )

        elif data == "settings:ffmpeg":
            await q.edit_message_text(
                f"üéöÔ∏è FFmpeg Audio Filter\n\n"
                f"Current filter:\n{self.ffmpeg_filter}\n\n"
                f"To change, send:\n/set_ffmpeg your_filter_here\n\n"
                f"Example:\n/set_ffmpeg afftdn=nr=12:nf=-25,highpass=f=80",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:audio_menu")]])
            )

        # 3. DEEPSEEK PROMPT MENU (Disabled - YouTube links now auto-process as Reference Audio)
        elif data == "settings:prompt_menu":
            await q.edit_message_text(
                "‚ÑπÔ∏è DeepSeek Feature Disabled\n\n"
                "YouTube links now automatically process as Reference Audio.\n\n"
                "üéµ Simply send a YouTube link and it will:\n"
                "‚Ä¢ Extract audio\n"
                "‚Ä¢ Crop to 30 seconds\n"
                "‚Ä¢ Set as voice reference",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
            )

        elif data == "settings:prompt_view":
            await q.edit_message_text(
                "‚ÑπÔ∏è Feature Not Available\n\n"
                "YouTube links now auto-process as Reference Audio.",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="main:settings")]])
            )

        elif data == "settings:prompt_help":
            await q.edit_message_text(
                "‚ÑπÔ∏è Feature Not Available\n\n"
                "YouTube links now auto-process as Reference Audio.",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="main:settings")]])
            )

        # 3B. YOUTUBE TRANSCRIPT PROMPT MENU (Disabled)
        elif data == "settings:youtube_prompt_menu":
            await q.edit_message_text(
                "‚ÑπÔ∏è YouTube Transcript Feature Disabled\n\n"
                "YouTube links now automatically process as Reference Audio only.",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
            )

        elif data == "settings:youtube_prompt_view":
            await q.edit_message_text(
                "‚ÑπÔ∏è Feature Not Available",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="main:settings")]])
            )

        elif data == "settings:youtube_prompt_help":
            await q.edit_message_text(
                "‚ÑπÔ∏è Feature Not Available",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="main:settings")]])
            )

        # 3C. AI MODE TOGGLE (Disabled)
        elif data == "settings:toggle_ai_mode":
            await q.edit_message_text(
                "‚ÑπÔ∏è AI Mode Feature Disabled\n\n"
                "YouTube links now automatically process as Reference Audio only.",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
            )

        # 3D. OPENROUTER MODEL SETTINGS
        elif data == "settings:openrouter_model":
            await q.edit_message_text(
                f"ü§ñ OpenRouter Model Settings\n\n"
                f"Current Model:\n{self.openrouter_model}\n\n"
                f"To change model, use:\n"
                f"/set_openrouter_model model_name\n\n"
                f"Popular models:\n"
                f"‚Ä¢ deepseek/deepseek-chat\n"
                f"‚Ä¢ anthropic/claude-3.5-sonnet\n"
                f"‚Ä¢ openai/gpt-4-turbo\n"
                f"‚Ä¢ google/gemini-pro-1.5\n"
                f"‚Ä¢ meta-llama/llama-3.1-70b-instruct\n\n"
                f"üí° This model is used when AI Mode is set to OpenRouter.",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
            )

        # 4. TITLE PROMPTS MENU
        elif data == "settings:title_prompts_menu":
            keyboard = [
                [InlineKeyboardButton("üìù Prompt 1 (Initial)", callback_data="settings:title_prompt1")],
                [InlineKeyboardButton("‚ú® Prompt 2 (Refine)", callback_data="settings:title_prompt2")],
                [InlineKeyboardButton("üíé Prompt 3 (Polish)", callback_data="settings:title_prompt3")],
                [InlineKeyboardButton("üî¢ Prompt (10 More)", callback_data="settings:title_prompt_10more")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            await q.edit_message_text(
                "üè∑Ô∏è Title Generation Prompts\n\n"
                "Manage AI prompts for video title generation:\n\n"
                "‚Ä¢ Prompt 1: Initial title generation\n"
                "‚Ä¢ Prompt 2: First refinement\n"
                "‚Ä¢ Prompt 3: Final polish\n"
                "‚Ä¢ 10 More: Generate 10 alternatives",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )

        elif data == "settings:title_prompt1":
            await q.edit_message_text(
                f"üìù Title Prompt 1 (Initial)\n\n"
                f"Current:\n{self.title_prompt_1}\n\n"
                f"To change:\n/set_title_prompt1 your_prompt_here",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:title_prompts_menu")]])
            )

        elif data == "settings:title_prompt2":
            await q.edit_message_text(
                f"‚ú® Title Prompt 2 (Refine)\n\n"
                f"Current:\n{self.title_prompt_2}\n\n"
                f"To change:\n/set_title_prompt2 your_prompt_here",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:title_prompts_menu")]])
            )

        elif data == "settings:title_prompt3":
            await q.edit_message_text(
                f"üíé Title Prompt 3 (Polish)\n\n"
                f"Current:\n{self.title_prompt_3}\n\n"
                f"To change:\n/set_title_prompt3 your_prompt_here",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:title_prompts_menu")]])
            )

        elif data == "settings:title_prompt_10more":
            await q.edit_message_text(
                f"üî¢ Title Prompt (10 More)\n\n"
                f"Current:\n{self.title_prompt_10_more}\n\n"
                f"To change:\n/set_title_prompt_10more your_prompt_here",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:title_prompts_menu")]])
            )

        # 5. POWER & CONTROL MENU
        elif data == "settings:power_menu":
            processing_status = "üîÑ Processing" if self.is_processing else "‚è∏Ô∏è Idle"

            keyboard = [
                [InlineKeyboardButton("‚ö° Power Policy", callback_data="settings:power_policy")],
                [InlineKeyboardButton("üõë Stop Processing", callback_data="settings:stop_processing")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            await q.edit_message_text(
                f"‚ö° Power & Control Menu\n\n"
                f"Status: {processing_status}\n"
                f"Policy: {self.power_policy}\n\n"
                f"Manage processing and power:",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )

        elif data == "settings:power_policy":
            await q.edit_message_text(
                f"‚ö° Power Policy Settings\n\n"
                f"Current: {self.power_policy}\n\n"
                f"Select action after all files finish:",
                parse_mode="Markdown",
                reply_markup=self._power_keyboard(self.power_policy)
            )

        elif data == "settings:stop_processing":
            if not self.is_processing:
                await q.answer("‚ö†Ô∏è No processing currently running", show_alert=True)
                return

            self.stop_requested = True
            await q.edit_message_text(
                "üõë STOP REQUESTED!\n\n"
                "‚è≥ Stopping current operation...\n"
                "üìä Queue will be cleared\n"
                "‚ö†Ô∏è Current file may be incomplete",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:power_menu")]])
            )

        # 6. COMPLETED FILES (LINKS)
        elif data == "settings:links":
            if not self.completed_files:
                await q.edit_message_text(
                    "üìù No completed files yet!",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
                )
                return

            links_text = f"üéâ Completed Files ({len(self.completed_files)}):\n\n"

            for i, file_info in enumerate(self.completed_files, 1):
                filename = file_info.get('filename', f'File {i}')
                link = file_info.get('link', 'No link')
                size = file_info.get('size', 'Unknown')

                links_text += f"{i}. üìÑ {filename}\n"
                links_text += f"   üìè Size: {size}\n"
                links_text += f"   üîó {link}\n\n"

            await q.edit_message_text(
                links_text,
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
            )

        # 7. DEBUG TOOLS
        elif data == "settings:debug":
            keyboard = [
                [InlineKeyboardButton("üß™ Run Test", callback_data="settings:run_test")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            await q.edit_message_text(
                "üîß Debug Tools\n\n"
                "Testing and debugging utilities:",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )

        # 8. PIPELINE MENU
        elif data == "settings:pipeline_menu":
            keyboard = [
                [InlineKeyboardButton("üìù Transcript", callback_data="pipeline:transcript")],
                [InlineKeyboardButton("üéØ Title Creation", callback_data="pipeline:title")],
                [InlineKeyboardButton("üñºÔ∏è Image Creation", callback_data="pipeline:image")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            await q.edit_message_text(
                "üîÑ Pipeline Menu\n\n"
                "Configure your content pipeline:",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )

        # Pipeline sub-menu handlers
        elif data == "pipeline:transcript":
            await q.edit_message_text(
                "üìù Transcript Settings\n\n"
                "Configure transcript generation settings here.\n\n"
                "üöß Coming soon - More options will be added!",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Pipeline", callback_data="settings:pipeline_menu")]])
            )

        elif data == "pipeline:title":
            await q.edit_message_text(
                "üéØ Title Creation Settings\n\n"
                "Configure title generation settings here.\n\n"
                "üöß Coming soon - More options will be added!",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Pipeline", callback_data="settings:pipeline_menu")]])
            )

        elif data == "pipeline:image":
            await q.edit_message_text(
                "üñºÔ∏è Image Creation Settings\n\n"
                "Configure image generation settings here.\n\n"
                "üöß Coming soon - More options will be added!",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Pipeline", callback_data="settings:pipeline_menu")]])
            )

        elif data == "settings:run_test":
            try:
                test_text = "This is a test script for F5-TTS."
                await q.edit_message_text("üß™ Running test...", reply_markup=None)

                # Run the test
                chat_id_test = q.message.chat.id if q.message else chat_id
                audio_paths = await self.generate_audio_f5(test_text, chat_id_test)

                if audio_paths:
                    await q.message.reply_text(
                        f"‚úÖ Test successful!\n\n"
                        f"Generated {len(audio_paths)} audio file(s)",
                        reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:debug")]])
                    )
                else:
                    await q.message.reply_text(
                        "‚ùå Test failed - no audio generated",
                        reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:debug")]])
                    )
            except Exception as e:
                await q.message.reply_text(
                    f"‚ùå Test error: {str(e)}",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back", callback_data="settings:debug")]])
                )


        # ====== OLD HANDLERS (KEEP FOR COMPATIBILITY) ======

        # Handle settings menu options
        elif data == "settings:ref":
            await q.edit_message_text(
                "üéµ Change Reference Audio\n\n"
                "Send a voice message or audio file to set as your new reference.\n\n"
                "Current reference: " + (os.path.basename(self.reference_audio) if self.reference_audio else "Not set"),
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
            )
            
        elif data == "settings:prompt":
            await q.edit_message_text(
                "üìù Set DeepSeek Prompt\n\n"
                f"Current prompt: {self.deepseek_prompt}\n\n"
                "To change the prompt, use the command:\n"
                "/set_prompt Your new prompt here",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
            )
            
        elif data == "settings:speed":
            # Create speed selection buttons
            keyboard = [
                [
                    InlineKeyboardButton("0.5x", callback_data="speed_0.5"),
                    InlineKeyboardButton("0.8x", callback_data="speed_0.8"),
                    InlineKeyboardButton("1.0x", callback_data="speed_1.0")
                ],
                [
                    InlineKeyboardButton("1.2x", callback_data="speed_1.2"),
                    InlineKeyboardButton("1.5x", callback_data="speed_1.5"),
                    InlineKeyboardButton("2.0x", callback_data="speed_2.0")
                ],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await q.edit_message_text(
                f"‚ö° Audio Speed Settings\n\n"
                f"Current speed: {self.audio_speed}x\n\n"
                f"Select new speed:",
                reply_markup=reply_markup
            )
            
        elif data == "settings:quality":
            # Create quality selection buttons
            keyboard = [
                [InlineKeyboardButton("Low (Faster)", callback_data="quality_low")],
                [InlineKeyboardButton("Medium", callback_data="quality_medium")],
                [InlineKeyboardButton("High (Better)", callback_data="quality_high")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await q.edit_message_text(
                f"üîß Audio Quality Settings\n\n"
                f"Current quality: {self.audio_quality}\n\n"
                f"Select new quality:",
                reply_markup=reply_markup
            )
            
        elif data == "settings:delivery":
            # Show delivery settings
            mode = self.delivery_prefs_by_chat.get(chat_id, "all")
            await q.edit_message_text(
                f"üìÑ Delivery Settings\n\n"
                f"Current setting: **{mode}**\n\n"
                f"Options:\n"
                f"‚Ä¢ All: Both Raw & Enhanced (default)\n"
                f"‚Ä¢ Enhanced: Noise reduction + EQ only\n"
                f"‚Ä¢ Raw: Unprocessed output only\n\n"
                f"Choose which audio format should be sent automatically.",
                parse_mode="Markdown",
                reply_markup=self._settings_keyboard(mode)
            )
            
        elif data == "settings:power":
            # Show power settings
            await q.edit_message_text(
                f"‚ö° Power Settings\n\n"
                f"Current policy: **{self.power_policy}**\n\n"
                f"Select what to do **after all files finish**:",
                parse_mode="Markdown",
                reply_markup=self._power_keyboard(self.power_policy)
            )
        
        # Handle delivery mode settings
        elif data.startswith("settings:set:"):
            new_mode = data.split(":", 2)[2]
            # validate
            allowed = {"enhanced", "raw", "all"}
            if new_mode not in allowed:
                await q.message.reply_text("‚ö†Ô∏è Invalid mode.")
                return

            self.delivery_prefs_by_chat[chat_id] = new_mode
            # Save configuration to file
            self.save_config()
            try:
                await q.edit_message_text(
                    text=f"‚úÖ Saved. Delivery setting: **{new_mode}**\n\nReturn to settings menu?",
                    parse_mode="Markdown",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]])
                )
            except Exception:
                # if edit fails (e.g., message old), just send a new message
                await q.message.reply_text(f"‚úÖ Saved. Delivery setting: **{new_mode}**", parse_mode="Markdown")
        
    async def handle_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Button callbacks handle kariye"""
        query = update.callback_query
        await query.answer()
        
        data = query.data
        
        if data.startswith("speed_"):
            self.audio_speed = float(data.replace("speed_", ""))
            # Save configuration to file
            self.save_config()
            # Show confirmation with back button
            keyboard = [[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(
                f"‚úÖ Speed set to {self.audio_speed}x and saved!\n\nReturn to settings?", 
                reply_markup=reply_markup
            )
            
        elif data.startswith("quality_"):
            self.audio_quality = data.replace("quality_", "")
            # Save configuration to file
            self.save_config()
            # Show confirmation with back button
            keyboard = [[InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(
                f"‚úÖ Quality set to {self.audio_quality} and saved!\n\nReturn to settings?", 
                reply_markup=reply_markup
            )
    
    async def links_command(self, update, context: ContextTypes.DEFAULT_TYPE):
        """All completed files links show kariye - works with both direct commands and callbacks"""
        # Handle both direct command and callback query
        is_callback = hasattr(update, 'callback_query')
        
        if is_callback:
            query = update.callback_query
            try:
                await query.answer()
            except:
                pass
        
        if not self.completed_files:
            message = "üìù No completed files yet!"
            if is_callback:
                keyboard = [[InlineKeyboardButton("üîô Back", callback_data="main:status")]]
                reply_markup = InlineKeyboardMarkup(keyboard)
                await query.edit_message_text(message, reply_markup=reply_markup)
            else:
                await update.message.reply_text(message)
            return
        
        links_text = f"üéâ Completed Files ({len(self.completed_files)}):\n\n"
        
        for i, file_info in enumerate(self.completed_files, 1):
            filename = file_info.get('filename', f'File {i}')
            link = file_info.get('link', 'No link')
            size = file_info.get('size', 'Unknown')
            
            links_text += f"{i}. üìÑ {filename}\n"
            links_text += f"   üìè Size: {size}\n"
            links_text += f"   üîó {link}\n\n"
        
        # Add back button if it's a callback
        if is_callback:
            keyboard = [[InlineKeyboardButton("üîô Back", callback_data="main:status")]]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(links_text, reply_markup=reply_markup)
        else:
            await update.message.reply_text(links_text)
    
    async def on_pick(self, update, context):
        q = update.callback_query
        try:
            await q.answer()
        except Exception:
            pass

        # ‚úÖ robust chat id for callbacks
        chat_id = None
        try:
            chat_id = q.message.chat.id if q and q.message and q.message.chat else None
        except Exception:
            chat_id = None
        if chat_id is None:
            # fallback to user id (last resort)
            chat_id = q.from_user.id if q and q.from_user else None

        if not chat_id:
            print("‚ö†Ô∏è on_pick: could not resolve chat_id")
            return

        data = q.data or ""
        print(f"üõ∞ on_pick received: {data} from chat {chat_id}")
        if not data.startswith("pick:"):
            return
        choice = data.split(":", 1)[1]

        if choice == "close":
            try:
                await q.edit_message_reply_markup(reply_markup=None)
            except Exception as e:
                print(f"on_pick close edit error: {e}")
            return

        rec = self.latest_outputs_by_chat.get(chat_id)
        if not rec or "paths" not in rec:
            print("on_pick: no recent outputs found for chat")
            await q.message.reply_text("‚ö†Ô∏è No recent output available.")
            return

        paths = rec["paths"]
        wanted = self._pick_paths(paths, choice)
        if not wanted:
            await q.message.reply_text("‚ö†Ô∏è Variant not found for this output.")
            return

        sent = 0
        for p in wanted:
            try:
                # cached link?
                link = rec.get("links", {}).get(p) or self.gofile_cache.get(p)
                if not link:
                    link = await self.upload_single_to_gofile(p)
                    if link:
                        rec.setdefault("links", {})[p] = link
                        self.gofile_cache[p] = link

                base = os.path.basename(p)
                size_mb = os.path.getsize(p) // (1024 * 1024) if os.path.exists(p) else 0

                if link:
                    await q.message.reply_text(f"üîó {base} ({size_mb}MB)\n{link}")
                    sent += 1
                else:
                    # Telegram fallback for small files
                    if os.path.exists(p) and os.path.getsize(p) < MAX_TELEGRAM_FILE_SIZE:
                        with open(p, "rb") as f:
                            await context.bot.send_audio(
                                chat_id=chat_id, audio=f,
                                caption=f"üìÑ {base} ({size_mb}MB) ‚Äî Telegram fallback"
                            )
                        sent += 1
                    else:
                        await q.message.reply_text(f"‚ö†Ô∏è Could not upload {base}; saved locally.")
            except Exception as e:
                print(f"on_pick loop error for {p}: {e}")
                try:
                    await q.message.reply_text(f"‚ö†Ô∏è Error delivering {os.path.basename(p)}: {e}")
                except Exception:
                    pass

        # keep the keyboard visible for more picks
        if sent and choice != "all":
            try:
                await q.edit_message_reply_markup(reply_markup=self._variant_keyboard())
            except Exception as e:
                print(f"on_pick edit_message_reply_markup error: {e}")



    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Text file documents handle kariye (supports channels and private chat)"""
        try:
            # Determine if this is a channel message
            chat_id = update.effective_chat.id
            is_channel = self.is_channel_message(update)

            # Channel authorization check
            if is_channel:
                if not self.is_authorized_channel(chat_id):
                    print(f"‚ö†Ô∏è Unauthorized channel attempted document upload: {chat_id}")
                    return
                print(f"üì¢ Channel document detected from: {chat_id}")

            # Get document from message or channel_post
            message_obj = update.message if update.message else update.channel_post
            document = message_obj.document

            # Check ki text file hai ya nahi
            if not document.file_name.endswith('.txt'):
                error_msg = "‚ùå Only .txt files supported!\nüìÑ Send text file with your script."
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=error_msg)
                else:
                    await update.message.reply_text(error_msg)
                return

            print(f"üìÑ Text file received: {document.file_name} ({'Channel' if is_channel else 'Private'})")

            # Send downloading message
            download_msg = "üìÑ Downloading text file..."
            if is_channel:
                await context.bot.send_message(chat_id=chat_id, text=download_msg)
            else:
                await update.message.reply_text(download_msg)

            # File download kariye
            file = await context.bot.get_file(document.file_id)
            file_path = os.path.join(SCRIPTS_DIR, document.file_name)

            # Download with longer timeout and better error handling
            try:
                # Send a progress message for large files
                file_size_mb = document.file_size / (1024 * 1024) if hasattr(document, 'file_size') else 0
                if file_size_mb > 5:  # For files larger than 5MB
                    progress_msg = (
                        f"üíæ Downloading large file ({file_size_mb:.1f}MB)...\n"
                        f"This might take some time. Please be patient."
                    )
                    if is_channel:
                        await context.bot.send_message(chat_id=chat_id, text=progress_msg)
                    else:
                        await update.message.reply_text(progress_msg)

                await asyncio.wait_for(
                    file.download_to_drive(file_path),
                    timeout=1000  # Increased to 120 seconds timeout
                )
            except asyncio.TimeoutError:
                timeout_msg = (
                    "‚ö†Ô∏è Download timed out! The file might be too large or network is slow.\n"
                    "Please try a smaller file or try again later."
                )
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=timeout_msg)
                else:
                    await update.message.reply_text(timeout_msg)
                return
            except Exception as download_error:
                error_msg = f"‚ùå Download error: {str(download_error)}"
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=error_msg)
                else:
                    await update.message.reply_text(error_msg)
                return

            # File content read kariye
            with open(file_path, 'r', encoding='utf-8') as f:
                script_content = f.read().strip()

            # ZERO Telegram messages - pure silent operation
            if not script_content:
                print(f"‚ö†Ô∏è Empty file skipped: {document.file_name}")
                return

            print(f"‚úÖ Text file loaded: {len(script_content)} characters from {document.file_name}")

            # COMPLETELY SILENT queuing - NO messages at all
            # Directly add to queue without calling process_text messaging
            timestamp = int(time.time() * 1000)
            filename = f"{document.file_name.replace('.txt', '')}_{timestamp}.txt"

            queue_item = {
                'script': script_content,
                'filename': filename,
                'timestamp': time.time(),
                'chat_id': chat_id,
                'is_channel': is_channel
            }
            self.processing_queue.append(queue_item)
            queue_size = len(self.processing_queue)

            print(f"üì• Queued silently: {document.file_name} (Queue: {queue_size})")

            # Start batch timer ONLY for first file, NO messages
            if not self.batch_mode and not self.is_processing and queue_size == 1:
                self.batch_mode = True
                self.queue_start_time = time.time()

                # Store context for channel processing
                if is_channel:
                    context._chat_id = chat_id

                # Start batch timer silently
                print(f"‚è≥ Batch timer started silently - {self.queue_wait_time}s")
                asyncio.create_task(self.start_batch_timer(context, chat_id))

        except Exception as e:
            # CRITICAL: NO Telegram messages in exception handler!
            # Only console logs to avoid flood control
            print(f"‚ùå Document processing error: {str(e)}")
            print(f"‚ö†Ô∏è File skipped due to error: {document.file_name}")

            # Don't try to send ANY Telegram messages - this causes flood control!
            # Just log the error and continue processing next files
    
    async def handle_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle text messages and YouTube links (supports both private chat and channels)"""
        try:
            chat_id = update.effective_chat.id
            is_channel = self.is_channel_message(update)

            # Channel authorization check
            if is_channel:
                if not self.is_authorized_channel(chat_id):
                    print(f"‚ö†Ô∏è Unauthorized channel attempted access: {chat_id}")
                    return
                print(f"üì¢ Channel message detected from: {chat_id}")

            script_text = update.message.text if update.message else update.channel_post.text
            print(f"üìù Text received ({('Channel' if is_channel else 'Private')}): {len(script_text)} characters")

            # Skip commands
            if script_text.startswith('/'):
                return

            # Check for YouTube links
            youtube_patterns = [
                r'(?:https?://)?(?:www\.)?(?:youtube\.com/watch\?v=|youtu\.be/)',
                r'youtube\.com/watch\?v=',
                r'youtu\.be/'
            ]

            # Extract all YouTube links from the message
            youtube_links = []
            for line in script_text.split():
                if any(re.search(pattern, line, re.IGNORECASE) for pattern in youtube_patterns):
                    youtube_links.append(line.strip())
            
            if youtube_links:
                # Automatically process YouTube link as Reference Audio (no options)
                for youtube_url in youtube_links:
                    # Prepare message text
                    msg_text = (
                        f"üîó YouTube link detected!\n\n"
                        f"üì∫ URL: {youtube_url[:50]}{'...' if len(youtube_url) > 50 else ''}\n\n"
                        f"üéµ Automatically processing as Reference Audio...\n"
                        f"üì• Extracting audio ‚Üí Cropping to 30s ‚Üí Setting as voice reference"
                    )

                    # Send notification and automatically process as reference audio
                    try:
                        if is_channel:
                            # For channel posts, send directly to channel
                            await context.bot.send_message(
                                chat_id=chat_id,
                                text=msg_text
                            )
                        else:
                            # For private chat, reply to message
                            await update.message.reply_text(msg_text)

                        # Automatically extract audio as reference (no user interaction needed)
                        print(f"üéµ Auto-processing YouTube link as Reference Audio: {youtube_url}")
                        await self.extract_youtube_audio_as_reference(youtube_url, update, context)

                    except Exception as e:
                        print(f"Error processing YouTube link: {e}")
                        error_msg = f"‚ùå Failed to process YouTube link: {str(e)[:100]}"
                        if is_channel:
                            await context.bot.send_message(chat_id=chat_id, text=error_msg)
                        else:
                            await update.message.reply_text(error_msg)
            else:
                await self.process_text(script_text, update, context)
            
        except Exception as e:
            error_msg = f"‚ùå Text handling error: {str(e)}"
            print(error_msg)
            # Handle reply for both channel and private chat
            try:
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=error_msg)
                else:
                    await update.message.reply_text(error_msg)
            except:
                print("Failed to send error message")
    
    async def process_text(self, script_text, update, context, silent=False, skip_errors=False):
        """Text process kariye with filename tracking (supports channel & private)

        Args:
            silent: If True, don't send intermediate messages (for batch uploads)
            skip_errors: If True, suppress error messages
        """
        try:
            # Get chat ID and determine if it's a channel
            chat_id = update.effective_chat.id
            is_channel = self.is_channel_message(update)

            # Prerequisites check
            if not self.f5_model:
                error_msg = "‚ùå F5-TTS not ready! Check installation."
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=error_msg)
                else:
                    await update.message.reply_text(error_msg)
                return

            if not self.reference_audio or not self.reference_text:
                error_msg = "‚ùå Reference audio missing! Add to reference/ folder and restart."
                if is_channel:
                    await context.bot.send_message(chat_id=chat_id, text=error_msg)
                else:
                    await update.message.reply_text(error_msg)
                return

            # Get filename if document was sent
            filename = "Direct Text"
            message_obj = update.message if update.message else update.channel_post
            if hasattr(message_obj, 'document') and message_obj.document:
                filename = message_obj.document.file_name
            elif is_channel:
                filename = "Channel Post"

            # Queue mein add kariye with filename and chat_id
            queue_item = {
                'script': script_text,
                'filename': filename,
                'timestamp': time.time(),
                'chat_id': chat_id,  # Store chat ID for response
                'is_channel': is_channel
            }
            self.processing_queue.append(queue_item)
            queue_size = len(self.processing_queue)

            # Batch mode logic - agar pehli file hai toh timer start karo
            if not self.batch_mode and not self.is_processing:
                self.batch_mode = True
                self.queue_start_time = time.time()

                # Only send message if not silent mode
                if not silent:
                    queue_msg = (
                        f"üìù File added to queue!\n"
                        f"üìÑ File: {filename}\n"
                        f"üìä Queue position: {queue_size}\n\n"
                        f"‚è≥ **BATCH MODE ACTIVATED**\n"
                        f"‚è±Ô∏è Waiting 2 minutes to collect all files...\n"
                        f"üì• Send more files now - they'll be queued!\n\n"
                        f"Processing will start automatically after 2 minutes."
                    )

                    try:
                        if is_channel:
                            await context.bot.send_message(chat_id=chat_id, text=queue_msg)
                        else:
                            await update.message.reply_text(queue_msg)
                    except Exception as msg_err:
                        if "Flood control" in str(msg_err):
                            print(f"‚ö†Ô∏è Flood control - skipping message for {filename}")
                        else:
                            print(f"Error sending queue message: {msg_err}")

                # Store context for channel processing
                if is_channel:
                    context._chat_id = chat_id

                # Start batch timer (2 minutes wait, then process)
                asyncio.create_task(self.start_batch_timer(context, chat_id))

            else:
                # Already in batch mode - silent mode or just log
                if not silent:
                    elapsed = int(time.time() - self.queue_start_time) if self.queue_start_time else 0
                    remaining = max(0, self.queue_wait_time - elapsed)

                    if self.batch_mode:
                        queue_msg = (
                            f"‚úÖ Added to batch queue!\n"
                            f"üìÑ File: {filename}\n"
                            f"üìä Total in queue: {queue_size}\n"
                            f"‚è±Ô∏è Time remaining: {remaining}s"
                        )
                    else:
                        # Processing already started
                        queue_msg = (
                            f"üìù Added to queue!\n"
                            f"üìÑ File: {filename}\n"
                            f"üìä Queue position: {queue_size}\n"
                            f"‚è≥ Currently processing..."
                        )

                    try:
                        if is_channel:
                            await context.bot.send_message(chat_id=chat_id, text=queue_msg)
                        else:
                            await update.message.reply_text(queue_msg)
                    except Exception as msg_err:
                        if "Flood control" in str(msg_err):
                            print(f"‚ö†Ô∏è Flood control - file {filename} queued silently (#{queue_size})")
                        else:
                            print(f"Error sending queue message: {msg_err}")
                
        except Exception as e:
            error_msg = f"‚ùå Process text error: {str(e)}"
            print(error_msg)

            # Only send error message if not in skip_errors mode
            if not skip_errors:
                try:
                    await update.message.reply_text(error_msg)
                except:
                    print("Could not send error message (likely flood control)")

    async def start_batch_timer(self, context, chat_id):
        """2 minutes wait karke batch processing start karo"""
        try:
            print(f"‚è≥ Batch timer started - waiting {self.queue_wait_time} seconds...")

            # Wait intervals with progress updates
            intervals = [30, 60, 90, 120]  # Progress at 30s, 1m, 1.5m, 2m
            last_time = 0

            for interval in intervals:
                wait_time = interval - last_time
                await asyncio.sleep(wait_time)
                last_time = interval

                remaining = self.queue_wait_time - interval
                queue_size = len(self.processing_queue)

                if remaining > 0:
                    # Progress update
                    progress_msg = (
                        f"‚è±Ô∏è Batch Timer Update\n"
                        f"üìä Files in queue: {queue_size}\n"
                        f"‚è≥ Time remaining: {remaining}s\n\n"
                        f"üí° Keep sending files - they'll be added to queue!"
                    )
                    try:
                        await context.bot.send_message(chat_id=chat_id, text=progress_msg)
                    except:
                        pass  # Ignore if send fails

            # Timer completed - start processing
            queue_count = len(self.processing_queue)
            print(f"‚úÖ Batch timer completed! Starting processing of {queue_count} files...")

            # Create detailed queue summary
            file_list = "\n".join([f"  {i+1}. {item['filename']}" for i, item in enumerate(self.processing_queue[:10])])
            if queue_count > 10:
                file_list += f"\n  ... and {queue_count - 10} more files"

            start_msg = (
                f"üöÄ **BATCH PROCESSING STARTING**\n\n"
                f"üìä Total files collected: {queue_count}\n"
                f"‚ö° Processing speed: {self.audio_speed}x\n"
                f"üîß Audio quality: {self.audio_quality}\n\n"
                f"üìù Files in queue:\n{file_list}\n\n"
                f"Processing files one by one...\n"
                f"You'll get updates for each completed file!"
            )

            try:
                await context.bot.send_message(chat_id=chat_id, text=start_msg)
            except:
                pass

            # Disable batch mode and start processing
            self.batch_mode = False

            # Start queue processing
            await self.process_queue(context)

        except Exception as e:
            print(f"‚ùå Batch timer error: {e}")
            self.batch_mode = False
            # Try to process anyway
            await self.process_queue(context)

    async def process_queue(self, context):
        """Queue process kariye - one by one files with individual completion"""
        if self.is_processing:
            print("‚ö†Ô∏è Already processing...")
            return

        # CRITICAL: Check if reference audio is set before processing
        if not self.reference_audio or not os.path.exists(self.reference_audio):
            error_msg = (
                "‚ùå **REFERENCE AUDIO NOT SET!**\n\n"
                "‚ö†Ô∏è Cannot process queue without reference audio.\n\n"
                "üìù **How to set reference audio:**\n"
                "1Ô∏è‚É£ Send a YouTube link (audio will auto-extract)\n"
                "2Ô∏è‚É£ Or send an MP3/audio file\n\n"
                f"üìä Files in queue: {len(self.processing_queue)}\n"
                "üí° Queue will be preserved - set reference audio and processing will start automatically!"
            )
            print(error_msg)

            # Send error to channel/chat
            try:
                actual_chat_id = context._chat_id if hasattr(context, '_chat_id') else CHAT_ID
                await context.bot.send_message(chat_id=actual_chat_id, text=error_msg)
            except:
                print("Failed to send reference audio error message")

            self.is_processing = False
            return

        self.is_processing = True
        self.stop_requested = False  # Reset stop flag
        print("üìÑ Queue processing started...")

        try:
            while self.processing_queue:
                # Check for stop request
                if self.stop_requested:
                    actual_chat_id = context._chat_id if hasattr(context, '_chat_id') else CHAT_ID
                    await context.bot.send_message(
                        chat_id=actual_chat_id,
                        text=f"üõë Processing stopped by user!\n\n"
                             f"üìä Remaining in queue: {len(self.processing_queue)}\n"
                             f"‚úÖ Completed before stop: {len(self.completed_files)}"
                    )
                    # Clear queue
                    self.processing_queue.clear()
                    self.stop_requested = False
                    break
                
                queue_item = self.processing_queue.pop(0)
                script_text = queue_item['script']
                filename = queue_item['filename']
                item_chat_id = queue_item.get('chat_id', CHAT_ID)  # Get chat ID from queue item
                is_channel_item = queue_item.get('is_channel', False)

                print(f"üìÑ Processing: {filename} ({len(script_text)} characters) for {'Channel' if is_channel_item else 'Private'} {item_chat_id}")

                # Use the chat ID from queue item (channel or private chat)
                actual_chat_id = item_chat_id

                # User ko notify kariye
                # Safe reference audio display (handle None case)
                ref_display = os.path.basename(self.reference_audio) if self.reference_audio else "‚ö†Ô∏è Not Set (using default)"

                await context.bot.send_message(
                    chat_id=actual_chat_id,
                    text=f"üìÑ Processing: {filename}\n\n"
                         f"üìù Script: {len(script_text)} characters\n"
                         f"üìå Preview: {script_text[:200]}{'...' if len(script_text) > 200 else ''}\n"
                         f"üéµ Reference: {ref_display}\n"
                         f"‚ö° Speed: {self.audio_speed}x\n"
                         f"üîß Quality: {self.audio_quality}\n\n"
                         f"‚è≥ Please wait, generation in progress...\n"
                         f"üõë Use /stop to cancel"
                )
                
                # Check stop before audio generation
                if self.stop_requested:
                    await context.bot.send_message(
                        chat_id=actual_chat_id,
                        text=f"üõë Stopped before generating: {filename}"
                    )
                    self.processing_queue.clear()
                    self.stop_requested = False
                    break
                
                # Store chat ID for chunk updates
                self._current_chat_id = actual_chat_id
                # Audio generate kariye (pass chat id)
                success, output_files = await self.generate_audio_f5(script_text, actual_chat_id)
                # Cleanup chunk progress context
                self._current_chat_id = None
                
                # Check if stopped during audio generation
                if self.stop_requested:
                    await context.bot.send_message(
                        chat_id=actual_chat_id,
                        text=(
                            f"üõë Processing stopped!\n\n"
                            f"üìÑ Last file: {filename}\n"
                            f"‚ö†Ô∏è Audio generation interrupted\n"
                            f"üìä Remaining: {len(self.processing_queue)} files"
                        )
                    )
                    self.processing_queue.clear()
                    self.stop_requested = False
                    break
                
                if success:
                    self.latest_outputs_by_chat[actual_chat_id] = {
                        "paths": output_files, "links": {}, "filename": filename, "ts": time.time()
                    }
                    link_or_status = await self.send_outputs_by_mode(context, actual_chat_id, output_files, script_text, filename)

                    # Track completed file(s)
                    total_bytes = sum(os.path.getsize(p) for p in output_files if os.path.exists(p))
                    self.completed_files.append({
                        'filename': filename,
                        'link': link_or_status,
                        'size': f"{total_bytes // (1024*1024)}MB",
                        'timestamp': time.time()
                    })
                    
                    # Individual completion message
                    remaining = len(self.processing_queue)
                    await context.bot.send_message(
                        chat_id=actual_chat_id,
                        text=f"‚úÖ {filename} completed!\n\n"
                             f"üìä Remaining in queue: {remaining}\n"
                             f"‚úÖ Total completed: {len(self.completed_files)}"
                    )
                    
                else:
                    await context.bot.send_message(
                        chat_id=actual_chat_id,
                        text=f"‚ùå {filename} failed!\n\n"
                             f"Error: {output_files}\n\n"
                             f"üîß Continuing with next file..."
                    )
                
                # Memory cleanup
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                await asyncio.sleep(2)  # Small delay between files
            
            # All files completed - Final summary (only for multiple files)
            if self.completed_files and len(self.completed_files) > 1:
                summary_text = f"üéâ ALL {len(self.completed_files)} FILES COMPLETED!\n\n"
                summary_text += f"üìä Total processed: {len(self.completed_files)} files\n"
                summary_text += f"‚ö° Speed used: {self.audio_speed}x\n"
                summary_text += f"üîß Quality: {self.audio_quality} ({64 if self.audio_quality == 'high' else 32} steps)\n\n"
                summary_text += f"üìã ALL DOWNLOAD LINKS:\n\n"
                
                for i, file_info in enumerate(self.completed_files, 1):
                    summary_text += f"{i}. üìÑ {file_info['filename']}\n"
                    summary_text += f"   üìè {file_info['size']}\n"
                    summary_text += f"   üîó {file_info['link']}\n\n"

                # Completion message removed - will show after video if created
                await context.bot.send_message(
                    chat_id=actual_chat_id,
                    text=summary_text
                )
            # No completion message here - let user decide about video first
            
        except Exception as e:
            error_msg = f"‚ùå Queue processing error: {str(e)}"
            print(error_msg)
            try:
                await context.bot.send_message(chat_id=actual_chat_id, text=error_msg)
            except:
                print("Could not send error message to user")
        finally:
            self.is_processing = False
            self.batch_mode = False  # Reset batch mode
            self.queue_start_time = None  # Reset timer
            print("‚úÖ Queue processing finished")
            try:
                await self.maybe_shutdown_after_queue(context, actual_chat_id)
            except Exception as _e:
                pass
    
    async def generate_audio_f5(self, script_text, chat_id=None):
        """F5-TTS API with PC-like parameters and processing"""
        try:
            # Optional chat context for progress updates
            if chat_id:
                self._current_chat_id = chat_id
            print(f"üîÑ F5-TTS generation starting...")
            print(f"üìù Script length: {len(script_text)} characters")
            print(f"üéµ Reference: {self.reference_audio}")
            
            # Create output filename
            timestamp = int(time.time())
            base_output_path = os.path.join(OUTPUT_DIR, f"generated_{timestamp}")
            raw_output = f"{base_output_path}_raw.wav"
            
            # Split text into chunks (configurable size)
            chunks = self.split_text_into_chunks(script_text, self.chunk_size)
            print(f"üìä Split into {len(chunks)} chunks ({self.chunk_size} chars each)")
            
            # Generate audio for each chunk
            audio_segments = []
            
            for i, chunk in enumerate(chunks):
                # Check for stop request BEFORE processing
                if self.stop_requested:
                    print(f"üõë Stop requested during chunk {i+1}/{len(chunks)}")
                    # Clean up and return immediately
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    return False, "Stopped by user"
                
                print(f"üìÑ Processing chunk {i+1}/{len(chunks)}")
                
                # Send chunk progress to Telegram (skip first chunk as it's already notified)
                if i > 0:  # Don't send for chunk 1 as it's already in the main processing message
                    try:
                        # Get chat ID from context (you'll need to pass it to this method)
                        if hasattr(self, '_current_chat_id') and self._current_chat_id:
                            await self._send_chunk_update(self._current_chat_id, i+1, len(chunks))
                            # Check again after sending update (user might have sent /stop)
                            if self.stop_requested:
                                print(f"üõë Stop requested after chunk update")
                                if torch.cuda.is_available():
                                    torch.cuda.empty_cache()
                                return False, "Stopped by user"
                    except Exception as e:
                        print(f"Failed to send chunk update: {e}")
                
                # Clear CUDA memory before each chunk
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # Check one more time before heavy processing
                if self.stop_requested:
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    return False, "Stopped by user"
                
                # F5-TTS API call with cached reference text and inference mode
                with torch.inference_mode():
                    result = self.f5_model.infer(
                        ref_file=self.reference_audio,
                        ref_text="",  # Let F5-TTS auto-extract to avoid cache conflicts
                        gen_text=chunk,
                        remove_silence=True,
                        cross_fade_duration=0.15,
                        speed=self.audio_speed,
                        nfe_step=32,
                        cfg_strength=1.5,
                        target_rms=0.1
                    )
                
                # Check after inference completes
                if self.stop_requested:
                    print(f"üõë Stop requested after inference chunk {i+1}")
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    return False, "Stopped by user"
                
                # Extract audio data
                if isinstance(result, tuple):
                    audio_data = result[0]
                else:
                    audio_data = result
                
                # Move to CPU to save VRAM
                if torch.is_tensor(audio_data):
                    audio_data = audio_data.cpu()
                
                audio_segments.append(audio_data)
                
                # Cleanup after each chunk
                del result
                import gc
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            print("üîó Combining audio segments...")
            
            # Concatenate all segments
            if torch.is_tensor(audio_segments[0]):
                final_audio = torch.cat(audio_segments, dim=-1).cpu()
            else:
                import numpy as np
                final_audio = np.concatenate(audio_segments)
            
            # Save raw audio first
            print(f"üíæ Saving raw audio...")
            if torch.is_tensor(final_audio):
                if final_audio.dim() == 1:
                    final_audio = final_audio.unsqueeze(0)
                import torchaudio
                torchaudio.save(raw_output, final_audio, 24000)
                audio_array = final_audio.squeeze().numpy()
            else:
                import soundfile as sf
                sf.write(raw_output, final_audio, 24000)
                audio_array = final_audio
            
            # Now create 4 versions like PC file
            output_files = await self.create_audio_variants(base_output_path, audio_array)
            
            print(f"‚úÖ Generated {len(output_files)} audio variants")
            return True, output_files
                
        except Exception as e:
            error_msg = f"F5-TTS generation error: {str(e)}"
            print(f"‚ùå {error_msg}")
            return False, error_msg
    
    def split_text_into_chunks(self, text, max_length):
        """Split text into chunks like PC version"""
        import re
        
        # Split by sentences first
        sentences = re.split(r'(?<=[.!?])\s+', text.strip())
        
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) > max_length:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = sentence
                else:
                    # Single sentence too long, force split
                    words = sentence.split()
                    temp_chunk = ""
                    for word in words:
                        if len(temp_chunk) + len(word) > max_length:
                            if temp_chunk:
                                chunks.append(temp_chunk.strip())
                                temp_chunk = word
                            else:
                                chunks.append(word)
                        else:
                            temp_chunk += " " + word if temp_chunk else word
                    current_chunk = temp_chunk
            else:
                current_chunk += " " + sentence if current_chunk else sentence
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    async def create_audio_variants(self, base_path, audio_array):
        """Create 2 audio variants: Raw and Enhanced (using ffmpeg filter)"""
        import numpy as np
        import subprocess
        import soundfile as sf
        
        output_files = []
        
        try:
            # 1. Raw audio (already saved)
            raw_file = f"{base_path}_raw.wav"
            output_files.append(raw_file)
            
            # 2. Enhanced audio with ffmpeg filter
            enhanced_file = f"{base_path}_enhanced.wav"
            ffmpeg_enhance_cmd = [
                'ffmpeg', '-i', raw_file,
                '-af', self.ffmpeg_filter,
                '-y', enhanced_file
            ]
            
            try:
                subprocess.run(ffmpeg_enhance_cmd, capture_output=True, check=True, timeout=60)
                output_files.append(enhanced_file)
                print("Enhanced audio created")
            except Exception as e:
                print(f"Enhanced audio creation failed: {e}")
                # Use raw as fallback
                import shutil
                shutil.copy(raw_file, enhanced_file)
                output_files.append(enhanced_file)
            
            return output_files
            
        except Exception as e:
            print(f"Audio variants creation error: {e}")
            return [raw_file] if os.path.exists(raw_file) else []

    async def send_audio_variants(self, context, file_paths, script_text, chat_id=None, filename="Generated Audio"):
        """
        Upload EACH variant individually to GoFile and send its link.
        No folder, no zip. Per-file retry+fallback. If a file fails to upload and is < 50MB, send via Telegram.
        """
        try:
            if chat_id is None:
                chat_id = CHAT_ID

            # Normalize
            if isinstance(file_paths, str):
                file_paths = [file_paths]
            file_paths = [p for p in file_paths if p and os.path.exists(p)]
            if not file_paths:
                await context.bot.send_message(chat_id=chat_id, text="‚ùå No output files found.")
                return "No files"

            results = []
            for p in file_paths:
                size_mb = os.path.getsize(p) // (1024 * 1024)
                base = os.path.basename(p)

                link = await self.upload_single_to_gofile(p)
                if link:
                    await context.bot.send_message(
                        chat_id=chat_id,
                        text=(
                            f"‚úÖ Uploaded: {base}\n"
                            f"üìè Size: {size_mb}MB\n"
                            f"üîó Link: {link}"
                        ),
                    )
                    results.append(link)
                    continue

                # Fallback: small files go via Telegram
                if os.path.getsize(p) < MAX_TELEGRAM_FILE_SIZE:
                    try:
                        with open(p, "rb") as f:
                            await context.bot.send_audio(
                                chat_id=chat_id,
                                audio=f,
                                caption=(
                                    f"‚úÖ {filename}\n"
                                    f"üìÑ Variant: {base}\n"
                                    f"üìè Size: {size_mb}MB\n"
                                    f"üéµ Ref: {os.path.basename(self.reference_audio)}\n"
                                    f"‚ö° Speed: {self.audio_speed}x"
                                )
                            )
                        results.append("Sent via Telegram")
                        continue
                    except Exception as e:
                        print(f"‚ö†Ô∏è Telegram fallback failed for {base}: {e}")

                # If we reach here, upload+fallback failed
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=f"‚ö†Ô∏è Could not deliver: {base}. File saved locally on server."
                )
                results.append("Local only")

            return ", ".join(results) if results else "Done"
        except Exception as e:
            err = f"Send audio variants error: {e}"
            print(f"‚ùå {err}")
            try:
                await context.bot.send_message(chat_id=chat_id or CHAT_ID, text=f"‚ùå {err}")
            except:
                pass
            return "Error"
    
    async def send_audio(self, context, audio_paths, script_text, chat_id=None, filename="Generated Audio"):
        """Send 4 variants if small; else upload all 4 to GoFile (one link). Returns 'Sent via Telegram' or URL."""
        try:
            if chat_id is None:
                chat_id = CHAT_ID

            # Normalize to list
            if not isinstance(audio_paths, list):
                audio_paths = [audio_paths]
            audio_paths = [p for p in audio_paths if p and os.path.exists(p)]
            if not audio_paths:
                raise RuntimeError("No audio files found to send.")

            sizes = [(p, os.path.getsize(p)) for p in audio_paths]
            total_mb = sum(sz for _, sz in sizes) // (1024 * 1024)
            any_too_big = any(sz >= MAX_TELEGRAM_FILE_SIZE for _, sz in sizes)

            if not any_too_big:
                # Send all variants to Telegram
                for p, sz in sizes:
                    caption = (
                        f"‚úÖ {filename}\n"
                        f"üìÑ Variant: {os.path.basename(p)}\n"
                        f"üìè Size: {sz // (1024*1024)}MB\n"
                        f"üìè Script: {len(script_text)} chars\n"
                        f"üéµ Ref: {os.path.basename(self.reference_audio)}\n"
                        f"‚ö° Speed: {self.audio_speed}x"
                    )
                    try:
                        if p.lower().endswith(".mp3"):
                            with open(p, "rb") as f:
                                await context.bot.send_audio(chat_id=chat_id, audio=f, caption=caption)
                        else:
                            with open(p, "rb") as f:
                                await context.bot.send_document(chat_id=chat_id, document=f, caption=caption)
                    except Exception as e:
                        print(f"‚ö†Ô∏è Failed to send {p}: {e}")
                print("‚úÖ All variants sent via Telegram")
                return "Sent via Telegram"

            # Too big: upload all 4 to one GoFile folder
            print("üîÑ One or more variants too large; uploading all 4 to a single GoFile link...")
            link = await self.upload_multiple_to_gofile(audio_paths)
            if link:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=(
                        f"‚úÖ {filename} (4 variants) uploaded to GoFile.\n\n"
                        f"üìä Total size: {total_mb}MB\n"
                        f"üîó Link: {link}\n\n"
                        f"üìè Script: {len(script_text)} chars\n"
                        f"üéµ Ref: {os.path.basename(self.reference_audio)}\n"
                        f"‚ö° Speed: {self.audio_speed}x"
                    ),
                )
                print("‚úÖ GoFile link sent")
                return link

            # If upload failed, still tell user where files are
            await context.bot.send_message(
                chat_id=chat_id,
                text=(
                    f"‚úÖ {filename} Generated & Saved locally.\n"
                    f"üìÅ Files: {', '.join([os.path.basename(p) for p in audio_paths])}\n"
                    f"‚ö†Ô∏è Upload failed."
                ),
            )
            return "Saved locally"
        except Exception as e:
            err = f"Send audio error: {str(e)}"
            print(f"‚ùå {err}")
            try:
                await context.bot.send_message(chat_id=chat_id or CHAT_ID, text=f"‚ùå {err}")
            except:
                pass
            return None
    
    async def upload_multiple_to_gofile(self, file_paths):
        """
        Upload multiple files to a SINGLE GoFile folder and return that folder's download page URL.
        If GOFILE_TOKEN is set, we include it for better control/quota.
        """
        try:
            token = os.getenv("GOFILE_TOKEN")  # optional
            headers = {"Authorization": f"Bearer {token}"} if token else {}
            folder_id = None
            download_page = None

            for path in file_paths:
                if not os.path.exists(path):
                    continue
                with open(path, "rb") as f:
                    data = {"folderId": folder_id} if folder_id else {}
                    files = {"file": f}
                    resp = requests.post(
                        "https://upload.gofile.io/uploadfile",
                        headers=headers,
                        data=data,
                        files=files,
                        timeout=1000
                    )
                resp.raise_for_status()
                j = resp.json()
                # GoFile returns info in "data"
                d = j.get("data", {}) if isinstance(j, dict) else {}
                # First upload creates a folder; subsequent uploads reuse it
                folder_id = d.get("folderId") or d.get("parentFolderId") or folder_id
                # Keep the folder's download page (user-facing page listing all files)
                download_page = download_page or d.get("downloadPage")

            return download_page
        except Exception as e:
            print(f"‚ùå GoFile multi-upload error: {e}")
            return None

    async def upload_single_to_gofile(self, file_path):
        """
        Upload exactly one file to GoFile and return its download page URL.
        Strategy:
          1) Try new API:   https://upload.gofile.io/uploadfile
          2) On 5xx/fail ‚Üí fallback to legacy server flow:
             - GET https://api.gofile.io/getServer
             - POST https://{server}.gofile.io/uploadFile
        Retries with exponential backoff.
        """
        token = os.getenv("GOFILE_TOKEN")  # optional
        headers = {"Authorization": f"Bearer {token}"} if token else {}

        def _try_new_api():
            with open(file_path, "rb") as f:
                resp = requests.post(
                    "https://upload.gofile.io/uploadfile",
                    headers=headers,
                    files={"file": f},
                    timeout=1000,
                )
            return resp

        def _try_legacy_api():
            # Get server
            srv = requests.get("https://api.gofile.io/getServer", timeout=15)
            srv.raise_for_status()
            server = srv.json().get("data", {}).get("server")
            if not server:
                raise RuntimeError("GoFile getServer returned no server.")
            # Upload to that server
            with open(file_path, "rb") as f:
                resp = requests.post(
                    f"https://{server}.gofile.io/uploadFile",
                    headers=headers,
                    files={"file": f},
                    timeout=1000,
                )
            return resp

        last_err = None
        for attempt in range(3):
            try:
                # 1) New API
                r = _try_new_api()
                if r.status_code == 200 and r.headers.get("content-type",""").startswith("application/json"):
                    j = r.json()
                    d = j.get("data", {}) if isinstance(j, dict) else {}
                    link = d.get("downloadPage")
                    if link:
                        return link
                # Fall back if 5xx or missing link
                # 2) Legacy server API
                r = _try_legacy_api()
                if r.status_code == 200 and r.headers.get("content-type",""").startswith("application/json"):
                    j = r.json()
                    # legacy returns {"status":"ok","data":{"downloadPage": "..."}}
                    if j.get("status") == "ok":
                        d = j.get("data", {})
                        link = d.get("downloadPage")
                        if link:
                            return link
                last_err = f"GoFile upload failed (attempt {attempt+1}): {r.status_code} {r.text[:200]}"
            except Exception as e:
                last_err = f"{type(e).__name__}: {e}"
            # backoff
            time.sleep(1.5 * (2 ** attempt))

        print(f"‚ùå GoFile single-upload error: {last_err}")
        return None

    def _classify_variant(self, path: str) -> str:
        p = path.lower()
        if p.endswith(".mp3"):
            return "mp3"
        if p.endswith("_loudness.wav"):
            return "loud"
        if p.endswith("_normalized.wav"):
            return "norm"
        if p.endswith(".wav"):
            return "raw"
        return "other"

    def _pick_paths(self, paths, which: str):
        if which == "all":
            return list(paths)
        if which == "enhanced":
            return [p for p in paths if p.endswith("_enhanced.wav")]
        if which == "raw":
            return [p for p in paths if p.endswith("_raw.wav")]
        # Default to all (both raw and enhanced)
        return list(paths)

    def _settings_keyboard(self, current: str):
        def label(mode, text):
            return f"‚úì {text}" if mode == current else text

        return InlineKeyboardMarkup([
            [
                InlineKeyboardButton(label("all", "All (default)"), callback_data="settings:set:all"),
            ],
            [
                InlineKeyboardButton(label("enhanced", "Enhanced"), callback_data="settings:set:enhanced"),
                InlineKeyboardButton(label("raw", "Raw"), callback_data="settings:set:raw"),
            ],
            [InlineKeyboardButton("Close", callback_data="settings:close")],
        ])

    def _variant_keyboard(self):
        return InlineKeyboardMarkup([
            [
                InlineKeyboardButton("üß∫ Both (default)", callback_data="pick:all"),
            ],
            [
                InlineKeyboardButton("üéß Enhanced", callback_data="pick:enhanced"),
                InlineKeyboardButton("üìº Raw", callback_data="pick:raw"),
            ],
            [
                InlineKeyboardButton("‚úï Close", callback_data="pick:close"),
            ],
        ])

    def _power_keyboard(self, current: str):
        def mark(opt, label):
            return f"‚úì {label}" if current == opt else label
        return InlineKeyboardMarkup([
            [InlineKeyboardButton(mark("off","Do nothing"),  callback_data="power:set:off")],
            [InlineKeyboardButton(mark("stop","Stop instance (safe)"), callback_data="power:set:stop")],
            [InlineKeyboardButton(mark("destroy","Destroy instance (danger)"), callback_data="power:set:destroy")],
            [InlineKeyboardButton("üîô Back", callback_data="settings:power_menu")]
        ])

    async def send_outputs_by_mode(self, context, chat_id, file_paths, script_text, filename):
        """
        Look up the saved mode for this chat and deliver exactly those variant links (no picker).
        """
        mode = self.delivery_prefs_by_chat.get(chat_id, "all")  # Default to all (both raw & enhanced)
        wanted = self._pick_paths(file_paths, mode)
        if not wanted:
            # fallback to 'raw' if the expected variant isn't present
            wanted = self._pick_paths(file_paths, "raw")

        results = []
        for p in wanted:
            # cached?
            link = self.gofile_cache.get(p)
            if not link:
                link = await self.upload_single_to_gofile(p)
                if link:
                    self.gofile_cache[p] = link

            base = os.path.basename(p)
            size_mb = os.path.getsize(p)//(1024*1024) if os.path.exists(p) else 0

            if link:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=f"üîó {base} ({size_mb}MB)\n{link}"
                )
                results.append(link)
            else:
                # small file Telegram fallback
                if os.path.exists(p) and os.path.getsize(p) < MAX_TELEGRAM_FILE_SIZE:
                    try:
                        with open(p, "rb") as f:
                            await context.bot.send_audio(
                                chat_id=chat_id, audio=f,
                                caption=f"üìÑ {base} ({size_mb}MB) ‚Äî Telegram fallback"
                            )
                        results.append("Sent via Telegram")
                    except Exception as e:
                        await context.bot.send_message(chat_id=chat_id, text=f"‚ö†Ô∏è Could not deliver {base}: {e}")
                else:
                    await context.bot.send_message(chat_id=chat_id, text=f"‚ö†Ô∏è Could not upload {base}; saved locally.")
                    results.append("Local only")

        return ", ".join(results) if results else "Done"

    async def power_command(self, update, context):
        chat_id = update.effective_chat.id
        await update.message.reply_text(
            f"‚ö° Power Settings\n\n"
            f"Current policy: **{self.power_policy}**\n\n"
            f"Select what to do **after all files finish**:",
            parse_mode="Markdown",
            reply_markup=self._power_keyboard(self.power_policy)
        )

    async def stop_processing_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Stop all ongoing processing immediately"""
        try:
            if not self.is_processing:
                await update.message.reply_text(
                    "‚ö†Ô∏è No processing currently running.\n\n"
                    "Use this command when audio/video generation is in progress."
                )
                return

            self.stop_requested = True

            await update.message.reply_text(
                "üõë STOP REQUESTED!\n\n"
                "‚è≥ Stopping current operation...\n"
                "üìä Current queue will be cleared\n"
                "‚ö†Ô∏è Current file may be incomplete\n\n"
                "Please wait a moment..."
            )

        except Exception as e:
            await update.message.reply_text(f"‚ùå Stop command error: {str(e)}")


    async def on_power(self, update, context):
        q = update.callback_query
        try: await q.answer()
        except: pass

        data = q.data or ""
        if data == "power:close":
            try: await q.edit_message_reply_markup(reply_markup=None)
            except: pass
            return

        if data.startswith("power:set:"):
            choice = data.split(":", 2)[2]
            if choice not in {"off","stop","destroy"}:
                await q.message.reply_text("‚ö†Ô∏è Invalid option.")
                return
            self.power_policy = choice
            # Save configuration to file
            self.save_config()
            warn = "\n\n‚ö†Ô∏è *Destroy deletes all data. Irreversible.*" if choice == "destroy" else ""
            try:
                await q.edit_message_text(
                    text=f"‚úÖ Saved. Power policy: **{choice}**{warn}",
                    parse_mode="Markdown",
                    reply_markup=self._power_keyboard(self.power_policy)
                )
            except:
                await q.message.reply_text(f"‚úÖ Saved. Power policy: **{choice}**{warn}", parse_mode="Markdown")

    async def on_process(self, update, context):
        """Handle process menu callbacks"""
        q = update.callback_query
        try:
            await q.answer()
        except:
            pass

        data = q.data or ""
        chat_id = q.message.chat.id if q and q.message and q.message.chat else None
        
        if data == "process:upload_txt":
            await q.edit_message_text(
                "üìÑ Please upload a text file (.txt) with your script content.\n\n"
                "The file will be processed automatically once uploaded."
            )
        
        elif data == "process:direct_text":
            await q.edit_message_text(
                "üìù Please type or paste your text directly in the chat.\n\n"
                "Your message will be processed automatically once sent."
            )
        
        elif data == "process:youtube":
            await q.edit_message_text(
                "üîó Please paste a YouTube link in the chat.\n\n"
                "The video transcript will be extracted, processed, and converted to audio.\n"
                "You can also send multiple YouTube links in one message."
            )
            
    async def on_status(self, update, context):
        """Handle status menu callbacks"""
        q = update.callback_query
        try:
            await q.answer()
        except:
            pass

        data = q.data or ""
        
        if data == "status:links":
            await self.links_command(update, context)
            
    async def on_ref(self, update, context):
        """Handle reference audio callbacks"""
        q = update.callback_query
        try:
            await q.answer()
        except:
            pass

        data = q.data or ""
        
        if data == "ref:back":
            # Load original reference
            self.load_manual_reference()
            
            ref_name = os.path.basename(self.reference_audio) if self.reference_audio else "None"
            
            # Create buttons for reference actions
            keyboard = [
                [InlineKeyboardButton("üéµ Set New Reference", callback_data="settings:ref")],
                [InlineKeyboardButton("üîô Back to Settings", callback_data="main:settings")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await q.edit_message_text(
                f"üîÑ Reverted to default reference!\n\n"
                f"üìÅ File: {ref_name}\n"
                f"üìù Text: {self.reference_text[:100]}{'...' if len(self.reference_text) > 100 else ''}\n\n"
                f"Choose an action:",
                reply_markup=reply_markup
            )

    async def on_youtube_mode(self, update, context):
        """Handle YouTube mode selection callbacks"""
        q = update.callback_query
        try:
            await q.answer()
        except:
            pass

        data = q.data or ""

        # Extract URL from callback data
        if not data.startswith("yt_mode:"):
            return

        parts = data.split(":", 2)
        if len(parts) < 3:
            await q.message.reply_text("‚ùå Invalid callback data")
            return

        mode = parts[1]  # 'ai' or 'ref'
        youtube_url = parts[2]

        if mode == "ai":
            # Process with AI (current flow)
            await q.edit_message_text("ü§ñ Processing with AI Mode (DeepSeek + F5-TTS)...")
            # Pass the update object directly, not q
            await self.process_youtube_link(youtube_url, update, context)

        elif mode == "ref":
            # Extract and set as reference
            await q.edit_message_text("üéµ Extracting audio as Reference...")
            # Pass the update object directly, not q
            await self.extract_youtube_audio_as_reference(youtube_url, update, context)


    # === Vast.ai helpers ===
    def _vast_headers(self):
        token = os.getenv("VAST_API_KEY")
        if not token:
            raise RuntimeError("VAST_API_KEY not set")
        return {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}

    def _vast_instance_id(self):
        iid = os.getenv("VAST_INSTANCE_ID") or os.getenv("CONTAINER_ID")
        if not iid:
            raise RuntimeError("VAST_INSTANCE_ID or CONTAINER_ID not set")
        return str(iid)

    def vast_stop_instance(self):
        """Stop Vast.ai instance using CLI (now that it's installed)"""
        try:
            # Method 1: Try to stop all instances
            try:
                result = subprocess.run(
                    ["vastai", "stop", "instance", "--all"],
                    capture_output=True,
                    text=True,
                    timeout=1000
                )
                print(f"CLI stop all result: {result.returncode}")
                print(f"Stdout: {result.stdout}")
                print(f"Stderr: {result.stderr}")
                
                if result.returncode == 0:
                    print("‚úÖ Vast.ai CLI stop --all successful")
                    return True
                else:
                    print(f"‚ö†Ô∏è Stop --all failed: {result.stderr}")
            except Exception as e:
                print(f"CLI --all method failed: {e}")
            
            # Method 2: Get instance list and stop individually
            try:
                list_result = subprocess.run(
                    ["vastai", "show", "instances"],
                    capture_output=True,
                    text=True,
                    timeout=1000
                )
                
                if list_result.returncode == 0 and list_result.stdout:
                    # Parse instance IDs from output
                    lines = list_result.stdout.strip().split('\n')
                    for line in lines[1:]:  # Skip header
                        parts = line.split()
                        if parts and parts[0].isdigit():
                            instance_id = parts[0]
                            # Try to stop this specific instance
                            stop_result = subprocess.run(
                                ["vastai", "stop", "instance", instance_id],
                                capture_output=True,
                                text=True,
                                timeout=1000
                            )
                            if stop_result.returncode == 0:
                                print(f"‚úÖ Stopped instance {instance_id}")
                                return True
                            else:
                                print(f"‚ö†Ô∏è Failed to stop {instance_id}: {stop_result.stderr}")
            except Exception as e:
                print(f"Individual stop method failed: {e}")
            
            # Method 3: API fallback (your previous working method)
            try:
                api_key = os.getenv("VAST_API_KEY")
                instance_id = os.getenv("VAST_INSTANCE_ID") or os.getenv("CONTAINER_ID")
                
                if api_key and instance_id:
                    headers = {
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    }
                    url = f"https://console.vast.ai/api/v0/instances/{instance_id}/"
                    
                    response = requests.put(
                        url, 
                        headers=headers, 
                        json={"state": "stopped"}, 
                        timeout=1000
                    )
                    
                    if response.status_code == 200:
                        print(f"‚úÖ API method stopped instance {instance_id}")
                        return True
                    else:
                        print(f"‚ö†Ô∏è API method failed: {response.status_code}")
                else:
                    print("‚ö†Ô∏è API credentials missing")
                    
            except Exception as e:
                print(f"API fallback failed: {e}")
            
            print("‚ùå All stop methods failed")
            return False
            
        except Exception as e:
            print(f"‚ùå Vast.ai stop error: {e}")
            return False

    def vast_destroy_instance(self):
        iid = self._vast_instance_id()
        url = f"https://console.vast.ai/api/v0/instances/{iid}/"
        for attempt in range(2):
            try:
                r = requests.delete(url, headers=self._vast_headers(), timeout=20)
                if r.status_code == 200:
                    return True
                time.sleep(1.5 * (2**attempt))
            except Exception:
                time.sleep(1.5 * (2**attempt))
        return False

    async def maybe_shutdown_after_queue(self, context, chat_id=None):
        if self.shutdown_executed:
            return

        policy = self.power_policy
        if policy == "off":
            return

        msg_chat = chat_id or (getattr(context, "chat_id", None) or None)
        
        try:
            # Clean all folders before shutdown
            await self.deep_cleanup_storage()
            
            if not self.vast_env_ok:
                if msg_chat:
                    await context.bot.send_message(
                        chat_id=msg_chat,
                        text="‚ö†Ô∏è Vast.ai environment not configured. Cleaned files but cannot auto-stop."
                    )
                return
            
            if policy == "stop":
                ok = self.vast_stop_instance()
                if msg_chat:
                    await context.bot.send_message(
                        chat_id=msg_chat,
                        text="üßπ Cleaned all files & folders.\nüõë " + 
                             ("‚úÖ Instance stopped successfully." if ok else "‚ö†Ô∏è Stop failed - check manually.")
                    )
            elif policy == "destroy":
                ok = self.vast_destroy_instance()
                if msg_chat:
                    await context.bot.send_message(
                        chat_id=msg_chat,
                        text="üßπ Cleaned all files & folders.\nüóëÔ∏è " + 
                             ("‚úÖ Instance destroyed." if ok else "‚ö†Ô∏è Destroy failed - check manually.")
                    )
            self.shutdown_executed = True
        except Exception as e:
            if msg_chat:
                await context.bot.send_message(chat_id=msg_chat, text=f"‚ö†Ô∏è Cleanup/shutdown error: {e}")

# Main function
async def async_main():
    """Async main bot function with proper initialization."""
    print("üöÄ Starting Final Working F5-TTS Bot...")

    # Bot instance
    bot_instance = WorkingF5Bot()

    if not bot_instance.f5_model:
        print("‚ùå F5-TTS initialization failed! Check installation.")
        return

    print("‚úÖ Bot fully initialized and ready!")

    # Display channel configuration
    print("\n" + "="*50)
    print("üì¢ CHANNEL CONFIGURATION")
    print("="*50)
    if CHANNEL_MODE_ENABLED:
        print("‚úÖ Channel Mode: ENABLED")
        if CHANNEL_IDS:
            print(f"üìã Authorized Channels: {len(CHANNEL_IDS)}")
            for ch_id in CHANNEL_IDS:
                print(f"   ‚Ä¢ Channel ID: {ch_id}")
        else:
            print("‚ö†Ô∏è No specific channels configured (accepting all)")
    else:
        print("‚ùå Channel Mode: DISABLED")
    print("="*50 + "\n")

    # Application with longer timeout for Vast.ai network
    application = (
        Application.builder()
        .token(BOT_TOKEN)
        .connect_timeout(60.0)
        .read_timeout(60.0)
        .write_timeout(60.0)
        .pool_timeout(60.0)
        .build()
    )

    # IMPORTANT: Initialize the application first
    await application.initialize()
    
    # Register handlers - START COMMAND FIRST
    # NOTE: Most commands now accessible via Settings menu for better organization
    application.add_handler(CommandHandler("start", bot_instance.start_command))
    application.add_handler(CommandHandler("settings", bot_instance.settings_command))

    # Keep these commands for text input convenience
    application.add_handler(CommandHandler("set_prompt", bot_instance.set_prompt_command))
    application.add_handler(CommandHandler("set_youtube_prompt", bot_instance.set_youtube_prompt_command))
    application.add_handler(CommandHandler("set_openrouter_model", bot_instance.set_openrouter_model_command))
    application.add_handler(CommandHandler("set_ffmpeg", bot_instance.set_ffmpeg_command))
    application.add_handler(CommandHandler("set_chunk_size", bot_instance.set_chunk_size_command))
    application.add_handler(CommandHandler("update_ytdlp", bot_instance.update_ytdlp_command))
    application.add_handler(CommandHandler("start_processing", bot_instance.start_processing_command))

    # All other commands accessible via Settings menu:
    # - Test: Settings > Debug Tools > Run Test
    # - Links: Settings > Completed Files
    # - Power: Settings > Power & Control
    # - Reference: Settings > Reference Audio
    # - Bulk: Settings > Bulk Shorts
    # - Stop: Settings > Power & Control > Stop Processing
    
    # Callback handlers
    application.add_handler(CallbackQueryHandler(bot_instance.on_main_menu, pattern=r"^main:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_pick, pattern=r"^pick:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_settings, pattern=r"^settings:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_settings, pattern=r"^pipeline:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_power, pattern=r"^power:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_process, pattern=r"^process:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_status, pattern=r"^status:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_ref, pattern=r"^ref:"))
    application.add_handler(CallbackQueryHandler(bot_instance.on_youtube_mode, pattern=r"^yt_mode:"))

    # Message handlers (order matters!)
    application.add_handler(MessageHandler(filters.AUDIO | filters.VOICE | filters.Document.AUDIO, bot_instance.test_audio_handler))
    application.add_handler(MessageHandler(filters.Document.TXT, bot_instance.handle_document))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, bot_instance.handle_text))

    # Channel post handlers (for channel messages)
    if CHANNEL_MODE_ENABLED:
        print("üì¢ Channel mode enabled - adding channel post handlers...")

        # Channel commands support
        application.add_handler(CommandHandler("set_ffmpeg", bot_instance.set_ffmpeg_command, filters=filters.ChatType.CHANNEL))

        # Channel text and file handlers
        application.add_handler(MessageHandler(filters.ChatType.CHANNEL & filters.Document.TXT, bot_instance.handle_document))
        application.add_handler(MessageHandler(filters.ChatType.CHANNEL & filters.TEXT & ~filters.COMMAND, bot_instance.handle_text))
        print(f"‚úÖ Channel handlers registered for {len(CHANNEL_IDS) if CHANNEL_IDS else 'all'} channel(s)")
        print(f"‚úÖ Channel commands enabled: /set_ffmpeg")

    print("‚úÖ All handlers registered")

    # Start the bot with proper async context
    print("üîÑ Starting bot polling...")
    await application.start()
    await application.updater.start_polling()

    print("‚úÖ Bot is now running! Press Ctrl+C to stop.")

    # Keep the bot running
    try:
        import signal
        stop_event = asyncio.Event()

        def signal_handler(sig, frame):
            stop_event.set()

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

        await stop_event.wait()
    except KeyboardInterrupt:
        pass
    finally:
        print("\nüõë Stopping bot...")
        await application.updater.stop()
        await application.stop()
        await application.shutdown()

def main():
    """Synchronous main entry point."""
    asyncio.run(async_main())

if __name__ == "__main__":
    main()